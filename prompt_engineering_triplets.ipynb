{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1029b029-4c8b-4740-8a71-b8a8fb3ac17c",
   "metadata": {},
   "source": [
    "# 1. bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ebe6e-bd29-4264-809a-f9de7153f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mettaleb/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-07 10:03:19.913679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759824199.937098 3988889 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759824199.944369 3988889 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-07 10:03:19.968327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/mettaleb/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "from groq import Groq\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4f765-3d0b-488c-a78a-db979645a559",
   "metadata": {},
   "source": [
    "# 2.Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345e2a2-f229-4841-a0fd-90459e5b89bf",
   "metadata": {},
   "source": [
    "Ce script charge le corpus JSON brut, extrait les textes, les tables et les triplets d’annotations, puis les organise dans une structure unifiée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a923e8-3528-4c5d-b2cb-af577a38b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/projects/melodi/mettaleb/Annotation/corpus_challenge/test/F2_nous.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "d = {}\n",
    "\n",
    "important_keys = ['Company type', 'Industry', 'Founded', 'Founder', 'Headquarters']\n",
    "\n",
    "for idx, doc in enumerate(data.get(\"documents\", [])):\n",
    "    texts = []\n",
    "    extraction_meta = doc.get(\"raw\", {}).get(\"_source\", {}).get(\"extractionMetadata\", [])\n",
    "    for meta in extraction_meta:\n",
    "        for t in meta.get(\"texts\", []):\n",
    "            texts.append(t.get(\"value\", \"\"))\n",
    "    texts = \" \".join(texts).strip()\n",
    "\n",
    "    tables = []\n",
    "    for meta in extraction_meta:\n",
    "        for tbl in meta.get(\"tables\", []):\n",
    "            table_data = tbl.get(\"tableData\", [])\n",
    "            cond1 = all(len(row) == 2 for row in table_data)\n",
    "            cond2 = len(table_data) > 0 and table_data[0] == ['0', '1']\n",
    "            cond3 = any(row[0] in important_keys for row in table_data[1:])\n",
    "\n",
    "            if cond1 and cond2 and cond3:\n",
    "                headers = [row[0] for row in table_data[1:]]\n",
    "                values = [row[1] for row in table_data[1:]]\n",
    "                new_table = {\"tableData\": [headers, values]}\n",
    "                tables.append(new_table)\n",
    "            else:\n",
    "                tables.append({\"tableData\": table_data})\n",
    "\n",
    "    triplets_list = []\n",
    "    for ann in doc.get(\"annotations\", []):\n",
    "        subj = ann.get(\"subject\", {}).get(\"annotationValue\", \"\")\n",
    "        obj = ann.get(\"object\", {}).get(\"annotationValue\", \"\")\n",
    "        pred_val = ann.get(\"predicate\", {}).get(\"entityValue\", \"\")\n",
    "        if pred_val.lower() == \"pertinence\":\n",
    "            continue\n",
    "        triplet_str = f\"{subj} ; {obj} ; {pred_val}\"\n",
    "        triplets_list.append(triplet_str)\n",
    "\n",
    "    triplets = \" | \".join(triplets_list)\n",
    "\n",
    "    d[idx] = [texts, tables, triplets]\n",
    "\n",
    "#for k, v in list(d.items())[:5]:\n",
    "#    print(f\"Doc {k}:\")\n",
    " #   print(\"  Text:\", v[0][:100], \"...\")\n",
    "  #  print(\"  Nb tables:\", len(v[1]))\n",
    "   # for t in v[1]:\n",
    "    #    print(\"  Table:\", t)\n",
    "    #print(\"  Triplets:\", v[2])\n",
    "   # print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c6c036-a544-4b09-abb8-46f71ca845dc",
   "metadata": {},
   "source": [
    "#### Convertit une table au format structurée CSV-like (string).\n",
    "Transforme une table extraite du corpus en un format lisible de type CSV, en normalisant les en-têtes et les lignes afin de faciliter son intégration dans les prompts des LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ca0171-d1d2-40b2-ba4d-8955ccb98e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_csvlike(table_dict):\n",
    "    table = table_dict.get(\"tableData\", [])\n",
    "    if not table:\n",
    "        return \"\"\n",
    "    headers = table[0]\n",
    "    headers = [h.strip() if h.strip() else f\"Col{i+1}\" for i, h in enumerate(headers)]\n",
    "    rows = table[1:]\n",
    "    csv_lines = [\" | \".join(headers)]\n",
    "    for row in rows:\n",
    "        row_extended = row + [\"\"] * (len(headers) - len(row))\n",
    "        csv_lines.append(\" | \".join(row_extended))\n",
    "    \n",
    "    return \"\\n\".join(csv_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21481611-d417-4045-8b7c-153425b3c5ee",
   "metadata": {},
   "source": [
    "## Liste des relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a583558a-3031-4f19-a77d-e9bc1fa3fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = ['acquired_by','brand_of', 'client_of', 'collaboration', 'competitor_of', 'merged_with', 'product_or_service_of', 'regulated_by', 'shareholder_of', 'subsidiary_of', 'traded_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b194c9-a71b-42da-a76d-2b1606089a55",
   "metadata": {},
   "source": [
    "# 3.Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47443fdd-e168-4b0a-b066-6cdebde1111c",
   "metadata": {},
   "source": [
    "Ce module définit les fonctions nécessaires pour interagir avec différents modèles de langage (en utilisant Groq ou Hugging Face), en configurant les appels API, les paramètres de génération (température, top-p, etc.) et les formats de messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17de2b-62e3-4f18-90ef-55410fb67626",
   "metadata": {},
   "source": [
    "## Avec Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1cc4cff6-6804-4daf-8035-c22be773dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "caffdae3-9c0d-4562-9029-05b348b964eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key= api_key)\n",
    "#DEFAULT_MODEL = \"llama-3.3-70b-versatile\"\n",
    "DEFAULT_MODEL = \"deepseek-r1-distill-llama-70b\"\n",
    "#DEFAULT_MODEL = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "def assistant(content: str):\n",
    "    return { \"role\": \"assistant\", \"content\": content }\n",
    "\n",
    "def user(content: str):\n",
    "    return { \"role\": \"user\", \"content\": content }\n",
    "\n",
    "def chat_completion(\n",
    "    messages: List[Dict],\n",
    "    model = DEFAULT_MODEL,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "        \n",
    "\n",
    "def completion(\n",
    "    prompt: str,\n",
    "    model: str = DEFAULT_MODEL,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    return chat_completion(\n",
    "        [user(prompt)],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "def complete_and_print(prompt: str, model: str = DEFAULT_MODEL):\n",
    "    #print(f'==============\\n{prompt}\\n==============')\n",
    "    response = completion(prompt, model)\n",
    "    #print(response, end='\\n\\n')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be4b22-b582-4418-b008-3c7f91912cf0",
   "metadata": {},
   "source": [
    "## Avec HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e524a5f-61bd-4bb5-a707-03393406a687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "#DEFAULT_MODEL = \"deepseek-ai/DeepSeek-V3.2-Exp\"\n",
    "#DEFAULT_MODEL = \"deepseek-ai/DeepSeek-R1\"\n",
    "DEFAULT_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
    "#DEFAULT_MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "#DEFAULT_MODEL = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "CACHE_DIR = \"/projects/melodi/mettaleb/huggingface_cache\"\n",
    "\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ab6de-0323-4b64-b5fa-d58220b9c833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6241f77-04f5-48ef-8f1b-66b6a9959dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "def assistant(content: str) -> Dict:\n",
    "    return {\"role\": \"assistant\", \"content\": content}\n",
    "\n",
    "def user(content: str) -> Dict:\n",
    "    return {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "\n",
    "def chat_completion(\n",
    "    messages: List[Dict],\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    \n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        prompt += f\"{role.upper()}:\\n{content}\\n\\n\"\n",
    "\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "def completion(\n",
    "    prompt: str,\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.1\n",
    ") -> str:\n",
    "    return chat_completion([user(prompt)], max_new_tokens, temperature, top_p)\n",
    "\n",
    "def complete_and_print(prompt: str):\n",
    "    response = completion(prompt)\n",
    "    print(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c961d99-cb3a-4cc4-a712-feb509eb2cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1911ee5-badc-4baf-85d8-417987a447e5",
   "metadata": {},
   "source": [
    "## 3.1 Zero-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98add4-ae59-46e9-8376-86467694b4d5",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "df8e8e00-fe68-43cb-ba3f-cf8fd3469710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupere_prompt(num_prompt, i):\n",
    "    if num_prompt == 1:\n",
    "        Prompt = f\"\"\"  \n",
    "        You are an expert in Natural Language Processing (NLP) specializing in relation extraction.  \n",
    "        Your task is to extract relations expressed strictly as triplets: (entity1, relation, entity2).  \n",
    "\n",
    "        Constraints:\n",
    "        - Both entity1 and entity2 must be valid named entities.  \n",
    "        - At least one entity must come from the text and the other from the table.  \n",
    "        - Only keep relations that are explicitly listed in the provided \"Possible relation types\".  \n",
    "        - Ignore any relation not in this list.  \n",
    "        - The extracted triplets must reflect connections valid, only when combining both sources (text + table), not when taken in isolation.  \n",
    "        - If no valid triplet exists, return \"NO_RELATION\".  \n",
    "        - Output must contain only the triplets in the required format. Do not include explanations, reasoning, or extra text.  \n",
    "\n",
    "        Output Format (strict):  \n",
    "        entity1, entity2: relation1 | entity3, entity4: relation2 | ...  \n",
    "\n",
    "        \n",
    "        Relation direction and semantics:\n",
    "        \n",
    "        - Use the conventional direction implied by the relation label. Examples if present in Possible relation types:\n",
    "            . Acquired_by: e2 purchases controlling stake in e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Brand of: e2 offers products or services of e1 (Brand). The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Client of: e1 uses (and presumably pays for) products or services offered by e2. The relation is directed. The inverted relation is best described by “Supplier of”.\n",
    "            . Collaboration: e1 and e2 collaborate in (parts of their) business activities. The relation is undirected.\n",
    "            . Competitor of: e1 competes for resources with e2. The relation is undirected.\n",
    "            . Merged with: e1 and e2 merged (parts of) their business activities. The relation is undirected.\n",
    "            . Product or service of: e1 is offered for commercial distribution by e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Regulated by: e2 regulates (parts of) the business activity of e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Shareholder of: e1 owns shares in e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Subsidiary of: e2 legally owns e1. The relation is directed. The inverted relation is best described by “Parent of”.\n",
    "            . Traded on: Shares of e1 are listed on e2 (Stock exchange). The relation is directed. The inverted relation is best described by “lists”.\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        Available Data:  \n",
    "        - Text segment: {v[0]}  \n",
    "        - Table content:\\n {table_to_csvlike(v[1][0])}  \n",
    "        - Possible relation types: [{relations}]  \n",
    "\n",
    "        Your task:  \n",
    "        1. Identify relations where one entity is in the text and the other in the table.  \n",
    "        2. Keep only relations that match the provided list. \n",
    "\"\"\"\n",
    "\n",
    "    if num_prompt == 2: # à utiliser avec le modèle LLaMA\n",
    "        Prompt = f\"\"\"\n",
    "                <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                As a Natural Language Processing (NLP) expert specializing in relation extraction.\n",
    "        Your task is to identify and extract valid relations expressed as triplets (entity1, relation, entity2) \n",
    "        from both a given text segment and a table content.\n",
    "        \n",
    "        Constraints:\n",
    "        - Both entity1 and entity2 must be valid named entities.\n",
    "        - Only extract relations where one entity is from the text and the other is from the table.\n",
    "        - Only use relations that are explicitly listed in the provided \"Possible relation types\".\n",
    "        - If no valid relation exists, return \"NO_RELATION\".\n",
    "        - The output must **only** contain the extracted triplets in the requested format, with no explanations, reasoning, or extra text.\n",
    "        \n",
    "        Output Format:\n",
    "        entity1, entity2: relation1 | entity3, entity4: relation2 | ...\n",
    "        \n",
    "        <|eot_id|>\n",
    "        \n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        You are provided with:\n",
    "        \n",
    "        - Text segment: {v[0]}\n",
    "        - Table content:\\n {table_to_csvlike(v[1][0])}\n",
    "        - Possible relation types: [{relations}]\n",
    "        \n",
    "        Your task:\n",
    "        1. Identify relations where at least one entity is in the text and the other in the table.\n",
    "        2. Construct relation triplets combining entities from both sources.\n",
    "        3. Only keep relations that match the provided list of relation types.\n",
    "        4. Return the result strictly in the format: entity1, entity2: relation1 | entity3, entity4: relation2\n",
    "        \n",
    "        If no valid relation exists, return \"NO_RELATION\".\n",
    "        \n",
    "        <|eot_id|>\n",
    "        \n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "    return Prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c314c8-cad4-4ab2-b526-fe83313e6a56",
   "metadata": {},
   "source": [
    "## 3.2 Few-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad2b0a-2108-47fd-8259-3666f98487c7",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ca2b3ff-20c7-491b-b568-35ad16ce62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = []\n",
    "texts = []\n",
    "tables = []\n",
    "for k, v in list(d.items()):\n",
    "    trilets_gold.append(v[2])\n",
    "    texts.append(v[0])\n",
    "    tables.append(table_to_csvlike(v[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e22c5c-6651-439e-8074-b9125d8ec479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae7cc1-455b-465e-8437-a2ee9b53204e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856005bb-6a64-4470-af75-277662c005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupere_prompt(num_prompt, i):\n",
    "    if num_prompt == 1:\n",
    "        Prompt = f\"\"\"  \n",
    "        You are an expert in Natural Language Processing (NLP) specializing in relation extraction.  \n",
    "        Your task is to extract relations expressed strictly as triplets: (entity1, relation, entity2).  \n",
    "\n",
    "        * Constraints:\n",
    "        - Both entity1 and entity2 must be valid named entities.  \n",
    "        - At least one entity must come from the text and the other from the table.  \n",
    "        - Only keep relations that are explicitly listed in the provided \"Possible relation types\".  \n",
    "        - Ignore any relation not in this list.  \n",
    "        - The extracted triplets must reflect connections valid, only when combining both sources (text + table), not when taken in isolation.  \n",
    "        - If no valid triplet exists, return \"NO_RELATION\".  \n",
    "        - Output must contain only the triplets in the required format. Do not include explanations, reasoning, or extra text.  \n",
    "\n",
    "        * Output Format (strict):  \n",
    "            entity1, entity2: relation1 | entity3, entity4: relation2 | ...  \n",
    "\n",
    "        \n",
    "        * Relation direction and semantics:\n",
    "        \n",
    "            - Use the conventional direction implied by the relation label. Examples if present in Possible relation types:\n",
    "                . Acquired_by: e2 purchases controlling stake in e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "                . Brand of: e2 offers products or services of e1 (Brand). The relation is directed. The inverted relation is best described by the same relation type.\n",
    "                . Client of: e1 uses (and presumably pays for) products or services offered by e2. The relation is directed. The inverted relation is best described by “Supplier of”.\n",
    "                . Collaboration: e1 and e2 collaborate in (parts of their) business activities. The relation is undirected.\n",
    "                . Competitor of: e1 competes for resources with e2. The relation is undirected.\n",
    "                . Merged with: e1 and e2 merged (parts of) their business activities. The relation is undirected.\n",
    "                . Product or service of: e1 is offered for commercial distribution by e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "                . Regulated by: e2 regulates (parts of) the business activity of e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "                . Shareholder of: e1 owns shares in e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "                . Subsidiary of: e2 legally owns e1. The relation is directed. The inverted relation is best described by “Parent of”.\n",
    "                . Traded on: Shares of e1 are listed on e2 (Stock exchange). The relation is directed. The inverted relation is best described by “lists”.\n",
    "            \n",
    "        \n",
    "\n",
    "        * Few-shot examples:\n",
    "        \n",
    "            - Example 1:\n",
    "                . Text: {texts[1]}\n",
    "                . Table:\\n{tables[1]}\n",
    "                . Output:\\n{trilets_gold[1]}\\n\\n  \n",
    "        \n",
    "            - Example 2:\n",
    "                . Text: {texts[4]}\n",
    "                . Table:\\n{tables[4]}\n",
    "                . Output:\\n{trilets_gold[4]} \\n\\n               \n",
    "            - Example 3:\n",
    "                . Text: {texts[5]}\n",
    "                . Table:\\n{tables[5]}\n",
    "                . Output: NO_RELATION\\n\\n  \n",
    "                \n",
    "        Now process the new data\n",
    "        \n",
    "        - Text: {v[0]}\n",
    "        - Table: {table_to_csvlike(v[1][0])}\n",
    "        - Output : \"\"\"\n",
    "        \n",
    "    if num_prompt == 2: # à utiliser avec le modèle LLaMA\n",
    "        Prompt = f\"\"\"\n",
    "          <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            You are an NLP expert specializing in cross-source relation extraction. Your goal is to output only valid relation triplets (entity1, relation, entity2) that are jointly supported by a free-text passage and a tabular dataset.\n",
    "            \n",
    "            Inputs\n",
    "            - Text\n",
    "            - Table (CSV-like string)\n",
    "            - Allowed relation types: [relations]\n",
    "            \n",
    "            Core requirements\n",
    "            - Named entities only: entity1 and entity2 must be proper-noun entities (persons, organizations, companies, locations, products). Do not use generic/common nouns (e.g., \"company\", \"city\") or pure numbers/dates unless they are part of a named entity.\n",
    "            - Cross-source constraint: each triplet must include at least one entity sourced from the text and at least one entity sourced from the table. If both entities appear in both sources, designate one as text-sourced and the other as table-sourced to satisfy the constraint.\n",
    "            - Relation validity: use only labels from \"Possible relation types\". Respect semantic direction implied by the label (e.g., founded_by: subject=organization/company, object=person).\n",
    "            - Evidence agreement: a triplet is valid only if (a) the text explicitly states or strongly implies the relation between the same two entities, and (b) the table contains those entities in the same row (across any columns). Table headers are not entities.\n",
    "            - Matching and canonicalization:\n",
    "              - Parse the first row as headers; subsequent rows are records.\n",
    "              - Consider entity pairs formed within the same row across columns; do not form pairs using headers.\n",
    "              - Match entities case-insensitively and after trimming whitespace.\n",
    "              - When an entity appears in both sources, prefer the table cell’s spelling for output; otherwise, use the text surface form.\n",
    "            - De-duplication and ordering: output each unique (entity1, relation, entity2) once. Sort triplets by relation, then entity1, then entity2 (case-insensitive) for deterministic output.\n",
    "            \n",
    "            Output format (strict)\n",
    "            - If at least one valid triplet exists, output them on a single line:\n",
    "              entity1, entity2: relation | entity3, entity4: relation | ...\n",
    "            - Use \", \" between entities, \": \" before the relation, and \" | \" between triplets.\n",
    "            - No trailing separator, no extra text, and no newline.\n",
    "            - Escaping: if an entity contains a comma, colon, or pipe, wrap it in double quotes and escape embedded quotes by doubling them (e.g., \"ACME, Inc.\").\n",
    "            - If no valid triplet exists, output exactly: NO_RELATION\n",
    "            \n",
    "            Procedure\n",
    "            1) Extract named entities from the text.\n",
    "            2) Parse the CSV-like table, collect cell values from each data row (ignore headers), and form candidate entity pairs within each row across columns.\n",
    "            3) For each candidate pair, check whether the text expresses one of the allowed relations between the same two entities; assign the correct label and direction.\n",
    "            4) Canonicalize entity strings, remove duplicates, sort (relation, entity1, entity2), and output in the strict format.\n",
    "            \n",
    "            Few-shot examples\n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            \\nExample 1:\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            Example 2:\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            \\nExample 3:\\n\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            Example 4 (no relation):\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: NO_RELATION\n",
    "            <|eot_id|>\n",
    "            \n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            Text: {v[0]}\n",
    "            Table: {table_to_csvlike(v[1][0])}\n",
    "            Possible relation types: [{relations}]\n",
    "            \n",
    "            Return only the triplets in the strict format.\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    return Prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74793a8-e683-497a-bce6-6444de232e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b2637-9b7c-4383-a628-52ce4d3768e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b66515f1-74f1-47b0-86f4-ac4941c8ff69",
   "metadata": {},
   "source": [
    "## 3.3 Lancer les prompts sur les LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81393552-eb59-4151-99f6-6c978ce71641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c06d95e4-cd90-4303-a4ae-1530fa604b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_instructions=[]\n",
    "for i, v in list(d.items()):\n",
    "    prompt = recupere_prompt(1, i)\n",
    "    demo_instructions.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "082455ed-8753-4d26-91cf-ed919ad3d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(demo_instructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b2ec224c-5ca9-4c22-86fb-ece02369186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultatsF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaed9f0-351c-4710-8ea7-ede889f9bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = []\n",
    "for inst in range(len(demo_instructions)):\n",
    "    reponse = complete_and_print(demo_instructions[inst])\n",
    "    resultats.append(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f4636365-3b08-4a70-86e1-3759ddded662",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultatsF = resultatsF + resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "27e3b10e-c9fb-4597-9901-2e9bcf7c50d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultatsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8124298-4caa-49c9-a4f3-d9b2973b3dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ee71ca7-01de-49cb-93de-5b6c910dfd0d",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "32b7a3eb-874d-4044-b5f0-41472d238017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(resultatsF)\n",
    "df.to_csv(\"results_fewshot_Llama4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9518dae-dbad-4054-83ab-486836a84e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99a1eeb-225d-4af2-8e36-826f435109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_result = pd.read_csv(\"results_fewshot_Llama4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb3017a-d020-4898-925f-4d9d98756b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_result= few_shot_result[\"0\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "528d8034-1ab0-469d-a4ba-40361245a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_result = zero_shot_result + resultatsF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbdb5a9-7254-4ffd-92ac-264667e65c04",
   "metadata": {},
   "source": [
    "#### Post-traitement (cas DeepSeek)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce1282-6504-4a7e-8b58-5ab4f42635ee",
   "metadata": {},
   "source": [
    "Ce script nettoie les réponses générées par le modèle DeepSeek en supprimant les balises de raisonnement internes (<think>...</think>) afin de ne conserver que le l'output final pertinent pour l’évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8479ea5e-9539-4dbf-82e4-2217afc6889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_output(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79d7c221-ccc9-4b82-9aee-83f19af1497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_resultF = []\n",
    "for output in few_shot_result:\n",
    "    cleaned = clean_output(output)\n",
    "    few_shot_resultF.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac964f7b-2b19-427b-9c9b-11dff6191bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5bab6-f792-4d6c-a560-f92ae190e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "134fa5e7-4e16-4662-b249-00c2ca270a00",
   "metadata": {},
   "source": [
    "## Preprocessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "20afb532-4f1a-414b-9fd5-848f981f16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ce script isole automatiquement les triplets valides (entité1 ; entité2 ; relation) à partir des réponses textuelles du modèle,\n",
    "#en filtrant les explications ou textes parasites souvent générés par les LLMs.\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_triplets(llm_output: str) -> str:\n",
    "    text = llm_output.strip()\n",
    "    pattern = r'([A-Za-z0-9\\s\\(\\)\\.\\-&]+)\\s*[,;:]\\s*([A-Za-z0-9\\s\\(\\)\\.\\-&]+)\\s*[,;:]\\s*([A-Za-z_]+)'\n",
    "\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    if not matches:\n",
    "        return \"NO_RELATION\"\n",
    "    \n",
    "    triplets = []\n",
    "    for e1, e2, rel in matches:\n",
    "        e1 = e1.strip()\n",
    "        e2 = e2.strip()\n",
    "        rel = rel.strip()\n",
    "        triplets.append(f\"{e1}; {e2}; {rel}\")\n",
    "    \n",
    "    triplets = list(dict.fromkeys(triplets))\n",
    "    return \" | \".join(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad6571bc-a4cd-435a-b966-6f0cf3b03413",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_resultF = []\n",
    "for x in resultatsF:\n",
    "    few_shot_resultF.append(extract_triplets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce887405-58cc-4664-b65c-75ad2224cdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587e2ab-ecf1-42ab-b828-80b0424e48bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "89e03d11-93e9-4079-9bcb-84ff9fe49618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c52388e8-e2aa-4995-b639-a8eee993f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Cette fonction uniformise la structure des triplets extraits, en harmonisant la casse et la mise en forme (entité1 ; entité2 ; relation),\n",
    "tout en filtrant les relations valides selon une liste prédéfinie.\"\"\"\n",
    "def extract_triplets_format(text):\n",
    "    triplets = []\n",
    "    \n",
    "    if not text.strip():\n",
    "        return triplets\n",
    "    \n",
    "    parts = re.split(r\"\\||\\n\", text)\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        if \";\" in part:\n",
    "            elems = [p.strip() for p in part.split(\";\")]\n",
    "            try:\n",
    "                if len(elems) == 3 and elems[1].lower() in relations or elems[2].lower() in relations:\n",
    "                    if elems[1].lower() in relations:\n",
    "                        triplets.append(f\"\"\"{elems[0].lower().replace(\" \",\"\")}; {elems[1].lower().replace(\" \",\"\")}; {elems[2].lower().replace(\" \",\"\")}\"\"\")\n",
    "                    elif elems[2].lower() in relations:\n",
    "                        triplets.append(f\"\"\"{elems[0].lower().replace(\" \",\"\")}; {elems[2].lower().replace(\" \",\"\")}; {elems[1].lower().replace(\" \",\"\")}\"\"\")\n",
    "            except:\n",
    "                triplets.append(\"x; NO_RELATION; x\")\n",
    "            continue\n",
    "        \n",
    "        m = re.match(r\"(.+?),\\s*(.+?):\\s*(\\w+)\", part)\n",
    "        if m:\n",
    "            e1, e2, rel = m.groups()\n",
    "            if rel in relations:\n",
    "                triplets.append(f\"\"\"{e1.strip().lower().replace(\" \",\"\")}; {rel.strip().lower().replace(\" \",\"\")}; {e2.strip().lower().replace(\" \",\"\")}\"\"\")\n",
    "    return triplets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "edff96c3-2013-4641-a63d-4edd6bdfca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_results = [extract_triplets_format(el) for el in few_shot_resultF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b1b5e691-add7-4d9d-9955-4d12c656e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = []\n",
    "for k, v in list(d.items()):\n",
    "    trilets_gold.append(v[2])\n",
    "    \n",
    "trilets_gold = [extract_triplets_format(el) for el in trilets_gold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8414de51-26c0-4cb1-8545-f3c365490773",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = trilets_gold[:238]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fcde3-8e46-46b3-9946-f2a7453b5433",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a00eda00-0e31-4251-a935-e53c20ef541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation_triplets import evaluation_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca5c8591-e24e-460f-9e9f-e8f63ae97c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluation_triplets(trilets_gold, few_shot_results, relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8af99f5f-007a-4cac-b97f-866d944aebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exact matching': {'precision': 0.23647499149370535, 'recall': 0.42795566502463056, 'f1': 0.3046241507779969}, 'Partial matching (head+tail)': {'precision': 0.290575025518884, 'recall': 0.5258620689655172, 'f1': 0.3743151435459127}, 'Partial matching (relation + 1 entity)': {'precision': 0.511058183055461, 'recall': 0.9248768472906403, 'f1': 0.6583388121849659}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d6480-410f-4027-bf97-22fd82da5f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9e092-737a-4748-a39f-0bd7f2200900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1ffd7-c241-4278-9397-a77beb843f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b6e62-ec93-4bb3-9596-f1008ec3e099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbe785-bc2d-4838-8c08-61391df60dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
