{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1029b029-4c8b-4740-8a71-b8a8fb3ac17c",
   "metadata": {},
   "source": [
    "# 1. bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ebe6e-bd29-4264-809a-f9de7153f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mettaleb/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-02 17:43:04.737442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759419785.028059 3834840 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759419785.105665 3834840 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-02 17:43:05.837590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "from groq import Groq\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4f765-3d0b-488c-a78a-db979645a559",
   "metadata": {},
   "source": [
    "# 2.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf4b46-2d85-4dcd-898a-3a150f50b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a923e8-3528-4c5d-b2cb-af577a38b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/projects/melodi/mettaleb/Annotation/corpus_challenge/test/F2_nous.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "d = {}\n",
    "\n",
    "important_keys = ['Company type', 'Industry', 'Founded', 'Founder', 'Headquarters']\n",
    "\n",
    "for idx, doc in enumerate(data.get(\"documents\", [])):\n",
    "    texts = []\n",
    "    extraction_meta = doc.get(\"raw\", {}).get(\"_source\", {}).get(\"extractionMetadata\", [])\n",
    "    for meta in extraction_meta:\n",
    "        for t in meta.get(\"texts\", []):\n",
    "            texts.append(t.get(\"value\", \"\"))\n",
    "    texts = \" \".join(texts).strip()\n",
    "\n",
    "    tables = []\n",
    "    for meta in extraction_meta:\n",
    "        for tbl in meta.get(\"tables\", []):\n",
    "            table_data = tbl.get(\"tableData\", [])\n",
    "            cond1 = all(len(row) == 2 for row in table_data)\n",
    "            cond2 = len(table_data) > 0 and table_data[0] == ['0', '1']\n",
    "            cond3 = any(row[0] in important_keys for row in table_data[1:])\n",
    "\n",
    "            if cond1 and cond2 and cond3:\n",
    "                headers = [row[0] for row in table_data[1:]]\n",
    "                values = [row[1] for row in table_data[1:]]\n",
    "                new_table = {\"tableData\": [headers, values]}\n",
    "                tables.append(new_table)\n",
    "            else:\n",
    "                tables.append({\"tableData\": table_data})\n",
    "\n",
    "    #TRIPLETS\n",
    "    triplets_list = []\n",
    "    for ann in doc.get(\"annotations\", []):\n",
    "        subj = ann.get(\"subject\", {}).get(\"annotationValue\", \"\")\n",
    "        obj = ann.get(\"object\", {}).get(\"annotationValue\", \"\")\n",
    "        pred_val = ann.get(\"predicate\", {}).get(\"entityValue\", \"\")\n",
    "        if pred_val.lower() == \"pertinence\":\n",
    "            continue\n",
    "        triplet_str = f\"{subj} ; {obj} ; {pred_val}\"\n",
    "        triplets_list.append(triplet_str)\n",
    "\n",
    "    triplets = \" | \".join(triplets_list)\n",
    "\n",
    "    #Sauvegarde\n",
    "    d[idx] = [texts, tables, triplets]\n",
    "\n",
    "#for k, v in list(d.items())[:5]:\n",
    "#    print(f\"Doc {k}:\")\n",
    " #   print(\"  Text:\", v[0][:100], \"...\")\n",
    "  #  print(\"  Nb tables:\", len(v[1]))\n",
    "   # for t in v[1]:\n",
    "    #    print(\"  Table:\", t)\n",
    "    #print(\"  Triplets:\", v[2])\n",
    "   # print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c6c036-a544-4b09-abb8-46f71ca845dc",
   "metadata": {},
   "source": [
    "#### Convertit une table au format structurée CSV-like (string).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ca0171-d1d2-40b2-ba4d-8955ccb98e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_csvlike(table_dict):\n",
    "    table = table_dict.get(\"tableData\", [])\n",
    "    if not table:\n",
    "        return \"\"\n",
    "    headers = table[0]\n",
    "    headers = [h.strip() if h.strip() else f\"Col{i+1}\" for i, h in enumerate(headers)]\n",
    "    rows = table[1:]\n",
    "    csv_lines = [\" | \".join(headers)]\n",
    "    for row in rows:\n",
    "        # Compléter si ligne plus courte\n",
    "        row_extended = row + [\"\"] * (len(headers) - len(row))\n",
    "        csv_lines.append(\" | \".join(row_extended))\n",
    "    \n",
    "    return \"\\n\".join(csv_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ffa724f-1713-4584-b119-1fde6b4cff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k, v in list(d.items())[:5]:\n",
    "#    print()\n",
    "#    print(table_to_csvlike(v[1][0]))\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a583558a-3031-4f19-a77d-e9bc1fa3fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = ['acquired_by','brand_of', 'client_of', 'collaboration', 'competitor_of', 'merged_with', 'product_or_service_of', 'regulated_by', 'shareholder_of', 'subsidiary_of', 'traded_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b194c9-a71b-42da-a76d-2b1606089a55",
   "metadata": {},
   "source": [
    "# 3.Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17de2b-62e3-4f18-90ef-55410fb67626",
   "metadata": {},
   "source": [
    "## Avec Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cc4cff6-6804-4daf-8035-c22be773dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caffdae3-9c0d-4562-9029-05b348b964eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key= api_key)\n",
    "#DEFAULT_MODEL = \"llama-3.3-70b-versatile\"\n",
    "DEFAULT_MODEL = \"deepseek-r1-distill-llama-70b\"\n",
    "def assistant(content: str):\n",
    "    return { \"role\": \"assistant\", \"content\": content }\n",
    "\n",
    "def user(content: str):\n",
    "    return { \"role\": \"user\", \"content\": content }\n",
    "\n",
    "def chat_completion(\n",
    "    messages: List[Dict],\n",
    "    model = DEFAULT_MODEL,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "        \n",
    "\n",
    "def completion(\n",
    "    prompt: str,\n",
    "    model: str = DEFAULT_MODEL,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    return chat_completion(\n",
    "        [user(prompt)],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "def complete_and_print(prompt: str, model: str = DEFAULT_MODEL):\n",
    "    #print(f'==============\\n{prompt}\\n==============')\n",
    "    response = completion(prompt, model)\n",
    "    #print(response, end='\\n\\n')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be4b22-b582-4418-b008-3c7f91912cf0",
   "metadata": {},
   "source": [
    "## Avec HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e524a5f-61bd-4bb5-a707-03393406a687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:41<00:00,  2.41s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#DEFAULT_MODEL = \"deepseek-ai/DeepSeek-V3.2-Exp\"\n",
    "#DEFAULT_MODEL = \"deepseek-ai/DeepSeek-R1\"\n",
    "DEFAULT_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
    "#DEFAULT_MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "#DEFAULT_MODEL = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "CACHE_DIR = \"/projects/melodi/mettaleb/huggingface_cache\"\n",
    "\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    device_map=\"auto\",  \n",
    "    dtype=dtype,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ab6de-0323-4b64-b5fa-d58220b9c833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6241f77-04f5-48ef-8f1b-66b6a9959dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "def assistant(content: str) -> Dict:\n",
    "    return {\"role\": \"assistant\", \"content\": content}\n",
    "\n",
    "def user(content: str) -> Dict:\n",
    "    return {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "\n",
    "def chat_completion(\n",
    "    messages: List[Dict],\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.2,\n",
    ") -> str:\n",
    "    \n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        prompt += f\"{role.upper()}:\\n{content}\\n\\n\"\n",
    "\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "def completion(\n",
    "    prompt: str,\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 0.95\n",
    ") -> str:\n",
    "    return chat_completion([user(prompt)], max_new_tokens, temperature, top_p)\n",
    "\n",
    "def complete_and_print(prompt: str):\n",
    "    response = completion(prompt)\n",
    "    print(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c961d99-cb3a-4cc4-a712-feb509eb2cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1911ee5-badc-4baf-85d8-417987a447e5",
   "metadata": {},
   "source": [
    "## 3.1 Zero-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98add4-ae59-46e9-8376-86467694b4d5",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8e8e00-fe68-43cb-ba3f-cf8fd3469710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupere_prompt(num_prompt, i):\n",
    "    if num_prompt == 1:\n",
    "        Prompt = f\"\"\"  \n",
    "        You are an NLP expert specializing in cross-source relation extraction between a free-text passage and a tabular dataset. Produce only valid relation triplets (entity1, relation, entity2) that connect at least one entity from the text with at least one entity from the table.\n",
    "        \n",
    "        Inputs:\n",
    "        - Text: {v[0]}\\n\n",
    "        - Table (CSV-like string):\\n {table_to_csvlike(v[1][0])}\\n\\n\n",
    "        - Allowed relation types: [relations]\n",
    "\n",
    "        \n",
    "        Global rules:\\n\n",
    "        - Output only triplets in the strict format defined below. Do not include explanations, notes, or extra text.\n",
    "        - Use only relation labels provided in \"Allowed relation types\". Ignore all other relation labels.\n",
    "        - Each triplet must include at least one text-sourced entity and at least one table-sourced entity.\n",
    "        - If no valid triplet exists, output exactly: \"NO_RELATION\"\n",
    "        \n",
    "        Entity requirements:\\n\n",
    "        - entity1 and entity2 must be named entities: proper-noun phrases referring to real-world entities. Do not use generic/common nouns (e.g., \"the company\", \"the city\").\n",
    "        - Text-sourced entities must be extracted from the text. Table-sourced entities must be taken from table cell values (not headers).\n",
    "      \n",
    "        Output format (strict):\n",
    "        \n",
    "        - If at least one valid triplet exists, output them on a single line using exactly: entity1, entity2: relation | entity3, entity4: relation | ...\n",
    "        - If none are valid, output exactly: NO_RELATION\n",
    "        \n",
    "        Return only the triplets in the strict output format.\n",
    "        \"\"\"\n",
    "    if num_prompt == 2:\n",
    "        Prompt = f\"\"\"\n",
    "        As a specialist in relation extraction, your task is to identify and output valid relational triplets from provided text and tabular data. \n",
    "        Each triplet should consist of two named entities (one from the text and one from the table) and a relation connecting them.\n",
    "        \n",
    "        - Follow these detailed guidelines:\n",
    "        \n",
    "            - Triplets Formation: \n",
    "                . Each triplet should link one entity from the text ('entity1') with one entity from the table ('entity2').\n",
    "                . Entity Requirements: Ensure both 'entity1' and 'entity2' are named entities.\n",
    "                . Relation Types: Use only the relation types listed in the provided 'Possible relation types'.\n",
    "                . Exclude any relations not listed.\n",
    "                . Contextual Validity: Validate relations based on the combined context of the text and the table. Ignore relations that are valid only in isolation.\n",
    "                . No Relation Scenario: If no valid relations are found, return 'NO_RELATION'.\n",
    "                . Output Format: Present your findings as a series of triplets in the format: 'entity1, entity2: relation1 | entity3, entity4: relation2 | ...', without additional text or explanations.\n",
    "                \n",
    "            - Data Inputs:\n",
    "                - Text: {v[0]}\\n  \n",
    "                - Table:\\n {table_to_csvlike(v[1][0])}\\n  \n",
    "                - Possible relation types: [{relations}]\\n\\n \n",
    "                \n",
    "            - Objective: \n",
    "                 -Analyze both the text and the table to extract all valid relation triplets. Ensure the output strictly adheres to the specified format.\n",
    "        \"\"\"\n",
    "    if num_prompt == 3:\n",
    "        Prompt = f\"\"\"  \n",
    "        You are an expert in Natural Language Processing (NLP) specializing in relation extraction.  \n",
    "        Your task is to extract relations expressed strictly as triplets: (entity1, relation, entity2).  \n",
    "\n",
    "        Constraints:\n",
    "        - Both entity1 and entity2 must be valid named entities.  \n",
    "        - At least one entity must come from the text and the other from the table.  \n",
    "        - Only keep relations that are explicitly listed in the provided \"Possible relation types\".  \n",
    "        - Ignore any relation not in this list.  \n",
    "        - The extracted triplets must reflect connections valid, only when combining both sources (text + table), not when taken in isolation.  \n",
    "        - If no valid triplet exists, return \"NO_RELATION\".  \n",
    "        - Output must contain only the triplets in the required format. Do not include explanations, reasoning, or extra text.  \n",
    "\n",
    "        Output Format (strict):  \n",
    "        entity1, entity2: relation1 | entity3, entity4: relation2 | ...  \n",
    "\n",
    "        Available Data:  \n",
    "        - Text segment: {v[0]}  \n",
    "        - Table content:\\n {table_to_csvlike(v[1][0])}  \n",
    "        - Possible relation types: [{relations}]  \n",
    "\n",
    "        Your task:  \n",
    "        1. Identify relations where one entity is in the text and the other in the table.  \n",
    "        2. Keep only relations that match the provided list.  \n",
    "        3. Return the result strictly in the format:  entity1, entity2: relation1 | entity3, entity4: relation2  \n",
    "        4. If no valid relation exists, return \"NO_RELATION\".  \n",
    "\"\"\"\n",
    "\n",
    "    if num_prompt == 4: # à utiliser avec le modèle LLaMA\n",
    "        Prompt = f\"\"\"\n",
    "                <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                As a Natural Language Processing (NLP) expert specializing in relation extraction.\n",
    "        Your task is to identify and extract valid relations expressed as triplets (entity1, relation, entity2) \n",
    "        from both a given text segment and a table content.\n",
    "        \n",
    "        Constraints:\n",
    "        - Both entity1 and entity2 must be valid named entities.\n",
    "        - Only extract relations where one entity is from the text and the other is from the table.\n",
    "        - Only use relations that are explicitly listed in the provided \"Possible relation types\".\n",
    "        - If no valid relation exists, return \"NO_RELATION\".\n",
    "        - The output must **only** contain the extracted triplets in the requested format, with no explanations, reasoning, or extra text.\n",
    "        \n",
    "        Output Format:\n",
    "        entity1, entity2: relation1 | entity3, entity4: relation2 | ...\n",
    "        \n",
    "        <|eot_id|>\n",
    "        \n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        You are provided with:\n",
    "        \n",
    "        - Text segment: {v[0]}\n",
    "        - Table content:\\n {table_to_csvlike(v[1][0])}\n",
    "        - Possible relation types: [{relations}]\n",
    "        \n",
    "        Your task:\n",
    "        1. Identify relations where at least one entity is in the text and the other in the table.\n",
    "        2. Construct relation triplets combining entities from both sources.\n",
    "        3. Only keep relations that match the provided list of relation types.\n",
    "        4. Return the result strictly in the format: entity1, entity2: relation1 | entity3, entity4: relation2\n",
    "        \n",
    "        If no valid relation exists, return \"NO_RELATION\".\n",
    "        \n",
    "        <|eot_id|>\n",
    "        \n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "    return Prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c314c8-cad4-4ab2-b526-fe83313e6a56",
   "metadata": {},
   "source": [
    "## 3.2 Few-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad2b0a-2108-47fd-8259-3666f98487c7",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca2b3ff-20c7-491b-b568-35ad16ce62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = []\n",
    "texts = []\n",
    "tables = []\n",
    "for k, v in list(d.items()):\n",
    "    trilets_gold.append(v[2])\n",
    "    texts.append(v[0])\n",
    "    tables.append(table_to_csvlike(v[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e22c5c-6651-439e-8074-b9125d8ec479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae7cc1-455b-465e-8437-a2ee9b53204e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "856005bb-6a64-4470-af75-277662c005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupere_prompt(num_prompt, i):\n",
    "    if num_prompt == 1:\n",
    "        Prompt = f\"\"\" You are a relation-extraction specialist. Extract cross-source relation triplets (entity1, relation, entity2)\n",
    "        by connecting one entity from the Text with one entity from the Table.\n",
    "\n",
    "        Inputs:\n",
    "        - Text\n",
    "        - Table (CSV-like)\n",
    "        - Possible relation types: [{relations}]\n",
    "        \n",
    "        Output format (strict):\n",
    "        - Return only triplets, no extra text, no explanations, and no newline: entity1, entity2: relation | entity3, entity4: relation | ...\n",
    "        - If no valid triplet exists, return exactly: NO_RELATION\n",
    "        \n",
    "        Core constraints:\n",
    "        - Cross-source requirement: In every triplet, one entity must come from the Text and the other from the Table.\n",
    "        - entity1 and entity2 must be named entities. Do not invent entities.\n",
    "        - Use only relation labels listed in Possible relation types, exactly as written.\n",
    "        - Do not infer relations that are not supported by the Text and/or Table.\n",
    "        \n",
    "        Relation direction and semantics:\n",
    "        - Use the conventional direction implied by the relation label. Examples if present in Possible relation types:\n",
    "            . Acquired_by: e2 purchases controlling stake in e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Brand of: e2 offers products or services of e1 (Brand). The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Client of: e1 uses (and presumably pays for) products or services offered by e2. The relation is directed. The inverted relation is best described by “Supplier of”.\n",
    "            . Collaboration: e1 and e2 collaborate in (parts of their) business activities. The relation is undirected.\n",
    "            . Competitor of: e1 competes for resources with e2. The relation is undirected.\n",
    "            . Merged with: e1 and e2 merged (parts of) their business activities. The relation is undirected.\n",
    "            . Product or service of: e1 is offered for commercial distribution by e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Regulated by: e2 regulates (parts of) the business activity of e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Shareholder of: e1 owns shares in e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
    "            . Subsidiary of: e2 legally owns e1. The relation is directed. The inverted relation is best described by “Parent of”.\n",
    "            . Traded on: Shares of e1 are listed on e2 (Stock exchange). The relation is directed. The inverted relation is best described by “lists”.\n",
    "\n",
    "        Processing steps:\n",
    "        \n",
    "        1. Parse the CSV-like table into header and rows.\n",
    "        2. Identify candidate named entities from text and table:\n",
    "        3. Generate candidate cross-source pairs (one from Text, one from Table).\n",
    "        4. Determine whether any relation from Possible relation types is supported by:\n",
    "            - Schema evidence from the Table (e.g., a header like \"Products\" can support Product_or_service_of between the row's entity and that cell), provided the relation is in the allowed list and direction is correct.\n",
    "        5. Keep only unambiguous, supported triplets that satisfy all constraints.\n",
    "        \n",
    "\n",
    "        Few-shot examples:\n",
    "        \n",
    "            - Example 1:\n",
    "                . Text: {texts[1]}\n",
    "                . Table:\\n{tables[1]}\n",
    "                . Output:\\n{trilets_gold[1]}\\n\\n  \n",
    "        \n",
    "            - Example 2:\n",
    "                . Text: {texts[4]}\n",
    "                . Table:\\n{tables[4]}\n",
    "                . Output:\\n{trilets_gold[4]} \\n\\n               \n",
    "            - Example 3:\n",
    "                . Text: {texts[5]}\n",
    "                . Table:\\n{tables[5]}\n",
    "                . Output: NO_RELATION\\n\\n  \n",
    "                \n",
    "        Now process the new data\n",
    "        \n",
    "        - Text: {v[0]}\n",
    "        - Table: {table_to_csvlike(v[1][0])}\n",
    "        - Output : \n",
    "        \n",
    "        Task Analyze the Text and the Table together and extract all valid cross-source relation triplets. Return only the triplets in the exact required format, or NO_RELATION if none. \"\"\"\n",
    "    if num_prompt == 2:\n",
    "        Prompt = f\"\"\"  \n",
    "            You are an NLP expert specializing in relation extraction. Extract cross-source relation triplets (entity1, relation, entity2)\n",
    "        by combining evidence from a text passage and a table.\n",
    "        \n",
    "        Task:\n",
    "        \n",
    "        - Identify relations where at least one entity is sourced from the text and at least one from the table.\n",
    "        - Construct valid triplets that use only relations from the provided list.\n",
    "        - Output only the triplets in the exact format specified below. If none are valid, output \"NO_RELATION\"\n",
    "        \n",
    "        Definitions and constraints:\n",
    "    \n",
    "        - Named entities: proper-noun phrases referring to real-world entities (e.g., persons, organizations, companies, locations, products). Do not use generic terms or common nouns.\n",
    "        - Entity sourcing:\n",
    "            . Text entities must be extracted from the text span.\n",
    "            . Table entities must be cell values from the table.\n",
    "            . Each triplet must include at least one entity sourced from the text and at least one sourced from the table.\n",
    "        - Relation validity:\n",
    "        - Use only relations listed in Allowed relation types\n",
    "        \n",
    "        Output format (strict)\n",
    "        \n",
    "        - If at least one valid triplet exists, output them on a single line using this exact pattern: entity1, entity2: relation | entity3, entity4: relation | ...\n",
    "        - No extra text, and no newline.\n",
    "        - If no valid triplet exists, output exactly: \"NO_RELATION\"\n",
    "        \n",
    "\n",
    "        Few-shot examples\n",
    "        \n",
    "        Example 1\n",
    "                . Text: \n",
    "                . Table:\n",
    "                . Allowed relation types: [{relations}]\n",
    "                . Output:\n",
    "        Example 2\n",
    "                . Text: \n",
    "                . Table:\n",
    "                . Allowed relation types: [{relations}]\n",
    "                . Output:\n",
    "        Example 3\n",
    "                . Text: \n",
    "                . Table:\n",
    "                . Allowed relation types: [{relations}]\n",
    "                . Output:\n",
    "        Example 4 (no relation)\n",
    "                . Text: \n",
    "                . Table:\n",
    "                . Allowed relation types: [{relations}]\n",
    "                . Output:\n",
    "                \n",
    "        New data\n",
    "        \n",
    "        - Text: {{text}}\n",
    "        - Table (CSV-like): {{table_csv}}\n",
    "        - Allowed relation types: [{relations}]\n",
    "        - Output:\n",
    "        Return only the triplets.\n",
    "            \"\"\"\n",
    "\n",
    "    if num_prompt == 3: # à utiliser avec le modèle LLaMA\n",
    "        Prompt = f\"\"\"\n",
    "          <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            You are an NLP expert specializing in cross-source relation extraction. Your goal is to output only valid relation triplets (entity1, relation, entity2) that are jointly supported by a free-text passage and a tabular dataset.\n",
    "            \n",
    "            Inputs\n",
    "            - Text\n",
    "            - Table (CSV-like string)\n",
    "            - Allowed relation types: [relations]\n",
    "            \n",
    "            Core requirements\n",
    "            - Named entities only: entity1 and entity2 must be proper-noun entities (persons, organizations, companies, locations, products). Do not use generic/common nouns (e.g., \"company\", \"city\") or pure numbers/dates unless they are part of a named entity.\n",
    "            - Cross-source constraint: each triplet must include at least one entity sourced from the text and at least one entity sourced from the table. If both entities appear in both sources, designate one as text-sourced and the other as table-sourced to satisfy the constraint.\n",
    "            - Relation validity: use only labels from \"Possible relation types\". Respect semantic direction implied by the label (e.g., founded_by: subject=organization/company, object=person).\n",
    "            - Evidence agreement: a triplet is valid only if (a) the text explicitly states or strongly implies the relation between the same two entities, and (b) the table contains those entities in the same row (across any columns). Table headers are not entities.\n",
    "            - Matching and canonicalization:\n",
    "              - Parse the first row as headers; subsequent rows are records.\n",
    "              - Consider entity pairs formed within the same row across columns; do not form pairs using headers.\n",
    "              - Match entities case-insensitively and after trimming whitespace.\n",
    "              - When an entity appears in both sources, prefer the table cell’s spelling for output; otherwise, use the text surface form.\n",
    "            - De-duplication and ordering: output each unique (entity1, relation, entity2) once. Sort triplets by relation, then entity1, then entity2 (case-insensitive) for deterministic output.\n",
    "            \n",
    "            Output format (strict)\n",
    "            - If at least one valid triplet exists, output them on a single line:\n",
    "              entity1, entity2: relation | entity3, entity4: relation | ...\n",
    "            - Use \", \" between entities, \": \" before the relation, and \" | \" between triplets.\n",
    "            - No trailing separator, no extra text, and no newline.\n",
    "            - Escaping: if an entity contains a comma, colon, or pipe, wrap it in double quotes and escape embedded quotes by doubling them (e.g., \"ACME, Inc.\").\n",
    "            - If no valid triplet exists, output exactly: NO_RELATION\n",
    "            \n",
    "            Procedure\n",
    "            1) Extract named entities from the text.\n",
    "            2) Parse the CSV-like table, collect cell values from each data row (ignore headers), and form candidate entity pairs within each row across columns.\n",
    "            3) For each candidate pair, check whether the text expresses one of the allowed relations between the same two entities; assign the correct label and direction.\n",
    "            4) Canonicalize entity strings, remove duplicates, sort (relation, entity1, entity2), and output in the strict format.\n",
    "            \n",
    "            Few-shot examples\n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            \\nExample 1:\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            Example 2:\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            \\nExample 3:\\n\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: \n",
    "            \n",
    "            Example 4 (no relation):\n",
    "            Text: \n",
    "            Table: \n",
    "            Relations: \n",
    "            Output: NO_RELATION\n",
    "            <|eot_id|>\n",
    "            \n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            Text: {v[0]}\n",
    "            Table: {table_to_csvlike(v[1][0])}\n",
    "            Possible relation types: [{relations}]\n",
    "            \n",
    "            Return only the triplets in the strict format.\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    return Prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74793a8-e683-497a-bce6-6444de232e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b2637-9b7c-4383-a628-52ce4d3768e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dc590-26c3-496f-892d-e3e2c3dc8b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81393552-eb59-4151-99f6-6c978ce71641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c06d95e4-cd90-4303-a4ae-1530fa604b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_instructions=[]\n",
    "for i, v in list(d.items()):\n",
    "    prompt = recupere_prompt(1, i)\n",
    "    demo_instructions.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "082455ed-8753-4d26-91cf-ed919ad3d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are a relation-extraction specialist. Extract cross-source relation triplets (entity1, relation, entity2)\n",
      "        by connecting one entity from the Text with one entity from the Table.\n",
      "\n",
      "        Inputs:\n",
      "        - Text\n",
      "        - Table (CSV-like)\n",
      "        - Possible relation types: [['acquired_by', 'brand_of', 'client_of', 'collaboration', 'competitor_of', 'merged_with', 'product_or_service_of', 'regulated_by', 'shareholder_of', 'subsidiary_of', 'traded_on']]\n",
      "        \n",
      "        Output format (strict):\n",
      "        - Return only triplets, no extra text, no explanations, and no newline: entity1, entity2: relation | entity3, entity4: relation | ...\n",
      "        - If no valid triplet exists, return exactly: NO_RELATION\n",
      "        \n",
      "        Core constraints:\n",
      "        - Cross-source requirement: In every triplet, one entity must come from the Text and the other from the Table.\n",
      "        - entity1 and entity2 must be named entities. Do not invent entities.\n",
      "        - Use only relation labels listed in Possible relation types, exactly as written.\n",
      "        - Do not infer relations that are not supported by the Text and/or Table.\n",
      "        \n",
      "        Relation direction and semantics:\n",
      "        - Use the conventional direction implied by the relation label. Examples if present in Possible relation types:\n",
      "            . Acquired_by: e2 purchases controlling stake in e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
      "            . Brand of: e2 offers products or services of e1 (Brand). The relation is directed. The inverted relation is best described by the same relation type.\n",
      "            . Client of: e1 uses (and presumably pays for) products or services offered by e2. The relation is directed. The inverted relation is best described by “Supplier of”.\n",
      "            . Collaboration: e1 and e2 collaborate in (parts of their) business activities. The relation is undirected.\n",
      "            . Competitor of: e1 competes for resources with e2. The relation is undirected.\n",
      "            . Merged with: e1 and e2 merged (parts of) their business activities. The relation is undirected.\n",
      "            . Product or service of: e1 is offered for commercial distribution by e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
      "            . Regulated by: e2 regulates (parts of) the business activity of e1. The relation is directed. The inverted relation is best described by the same relation type.\n",
      "            . Shareholder of: e1 owns shares in e2. The relation is directed. The inverted relation is best described by the same relation type.\n",
      "            . Subsidiary of: e2 legally owns e1. The relation is directed. The inverted relation is best described by “Parent of”.\n",
      "            . Traded on: Shares of e1 are listed on e2 (Stock exchange). The relation is directed. The inverted relation is best described by “lists”.\n",
      "\n",
      "        Processing steps:\n",
      "        \n",
      "        1. Parse the CSV-like table into header and rows.\n",
      "        2. Identify candidate named entities from text and table:\n",
      "        3. Generate candidate cross-source pairs (one from Text, one from Table).\n",
      "        4. Determine whether any relation from Possible relation types is supported by:\n",
      "            - Schema evidence from the Table (e.g., a header like \"Products\" can support Product_or_service_of between the row's entity and that cell), provided the relation is in the allowed list and direction is correct.\n",
      "        5. Keep only unambiguous, supported triplets that satisfy all constraints.\n",
      "        \n",
      "\n",
      "        Few-shot examples:\n",
      "        \n",
      "            - Example 1:\n",
      "                . Text: Spanfeller Media Group(SMG), asubsidiaryof publishing companyTribune Publishing, is adigital mediacompany based inNew York City. It was founded in 2010 byJim Spanfeller, after leading the digital strategy at Forbes.com. Spanfeller Media Group operates two media sites as subject-specific digital destinations,The Daily Meal, dedicated to food and drink, andThe Active Times, centered on outdoor sports and an active lifestyle.[1][2][3].\n",
      "\n",
      "Tribune Publishing (known asTroncat time), noted in theirForm 10-Kfor the fiscal year of 2017 that they had \"completed acquisitions totaling $7.6 million of Spanfeller Media Group (SMG)\".[6].\n",
      "\n",
      "SMG’s executive team comprises Jim Spanfeller, President & CEO; Jeff Bauer, Chief Product Officer; Jacqueline Stone, Senior Vice President, Marketing; Philip Barber, Chief Technology Officer; Sharon Jautz, Vice President, Human Resources. Spanfeller previously served as the President and CEO of Forbes.com, serving on the advisory boards of several early-stage Web start-ups. He has received numerous industry accolades such as the first ever Founders Award from the Interactive Advertising Bureau (IAB) for lifetime achievement. Currently, Spanfeller is Secretary of the Online Publisher’s Association (OPA) and is a Chairman Emeritus of the IAB.\n",
      "                . Table:\n",
      "Col1 | Industry | Founded | Headquarters | Key people | Parent\n",
      " | Publishing | 1 January 2010 | New York City | Jim Spanfeller | Tribune Publishing\n",
      "                . Output:\n",
      "Tribune Publishing ; Spanfeller Media Group(SMG) ; subsidiary_of\n",
      "\n",
      "  \n",
      "        \n",
      "            - Example 2:\n",
      "                . Text: The studio producedMagizh Thirumeni'sMundhinam Paartheney(2010) featuring newcomers Sanjay, Ekta Ghosla, Lizna, Pooja andVithagan(2011) starringParthibanandPoorna.[10][11]In the early 2010s, Seventh Channel collaborated withStar Vijayto dub and releaseMahabharat(2013) in the Tamil language.[12]\n",
      "                . Table:\n",
      "Title | Year | Language | Director | Cast | Synopsis | Ref.\n",
      "Pudhiya Thendral | 1993 | Tamil | Prabhakar | Ramesh Aravind, Sivaranjani, Radhika |  | \n",
      "Coolie | 1995 | Tamil | P. Vasu | Sarathkumar, Meena, Kavitha Vijayakumar |  | \n",
      "Maanbumigu Maanavan | 1996 | Tamil | S. A. Chandrasekhar | Vijay, Swapna Bedi, Mansoor Ali Khan |  | \n",
      "Seenu | 2000 | Tamil | P. Vasu | Karthik, Malavika, P. Vasu |  | \n",
      "Vettaiyaadu Vilaiyaadu | 2006 | Tamil | Gautham Vasudev Menon | Kamal Haasan, Jyothika, Kamalinee Mukherjee |  | [13]\n",
      "Indiralohathil Na Azhagappan | 2008 | Tamil | Thambi Ramaiah | Vadivelu, Yamini Sharma, Suja Varunee |  | [14]\n",
      "Mundhinam Paartheney | 2010 | Tamil | Magizh Thirumeni | Sanjay, Ekta Ghosla, Lizna, Pooja |  | [15]\n",
      "Vithagan | 2011 | Tamil | R. Parthiban | Parthiban, Poorna, Milind Soman |  | [16]\n",
      "                . Output:\n",
      "Maanbumigu Maanavan ; Seventh Channel ; product_or_service_of | Seenu ; Seventh Channel ; product_or_service_of | Vettaiyaadu Vilaiyaadu ; Seventh Channel ; product_or_service_of | Vithagan ; Seventh Channel ; product_or_service_of | Indiralohathil Na Azhagappan ; Seventh Channel ; product_or_service_of | Mundhinam Paartheney ; Seventh Channel ; product_or_service_of | Pudhiya Thendral ; Seventh Channel ; product_or_service_of | Coolie ; Seventh Channel ; product_or_service_of \n",
      "\n",
      "               \n",
      "            - Example 3:\n",
      "                . Text: Simulations Canadais a Canadian boardwargamepublisher established in Nova Scotia in 1977, before moving to Vancouver Island, British Columbia. The company was founded by Stephen Newberg as a one-man operation and was one of only a handful of companies devoted to publishing wargames at that time. Other companies such asAvalon HillandSimulations Publications, Inc. did not accept unsolicited submissions, resulting in the creation of the company.[citation needed].\n",
      "\n",
      "Thisboard game-related article or section is astub. You can help Wikipedia byexpanding it.\n",
      "                . Table:\n",
      "Industry | Founded | Headquarters | Key people | Products\n",
      "Gaming | 1977 | British Columbia, Canada (formerly Bridgewater, Nova Scotia) | Stephen Newberg | Board games, wargames\n",
      "                . Output: NO_RELATION\n",
      "\n",
      "  \n",
      "                \n",
      "        Now process the new data\n",
      "        \n",
      "        - Text: GV Filmsis an Indianfilm productionanddistributioncompany headed byIshari K. Ganesh. The firm had been a leading production studio in the Tamil film industry in the 1990s and had been founded byG. Venkateswaranas Sujatha Films in 1986.[1][2].\n",
      "\n",
      "Sujatha Films was set up in 1986 byG. Venkateswaran, a chartered accountant, as a film production and distribution company. Operating as a family production house, Venkateswaran's brotherMani Ratnamalso often assisted on the production work of films that he directed for the studio.[3]Sujatha Films became GV Films as it became the first publicly listed company from the Indian media industry in 1989.[4].\n",
      "\n",
      "Following Venkateswaran's death, the studio continued to produce media content under the same name. Notably, actressManisha Koiralawas briefly a board member as the studio attempted to make a comeback through Hindi film content and 3D television serials.[13]The studio launched a big budget Hindi film directed byMahesh ManjrekarstarringSanjay Duttin late 2005, though it was later stalled.[14]Kasthuri Shankaralso worked with the studio and assisted on the oversight of the production ofUrchagam(2007).[15]The studio returned to prioritising distribution ventures and instead chose to make small budget films such asKaivantha Kalai(2006) andThirudi(2006).[16]In 2015, GV Films held a ceremony in Mumbai to mark 25 years since its founding.[17]\n",
      "        - Table: Company type | Industry | Founded | Founder | Headquarters | Products\n",
      "Film production Film distribution | Entertainment | 1989 | G. Venkateswaran | Chennai, India | Motion pictures (Tamil)\n",
      "        - Output : \n",
      "        \n",
      "        Task Analyze the Text and the Table together and extract all valid cross-source relation triplets. Return only the triplets in the exact required format, or NO_RELATION if none. \n"
     ]
    }
   ],
   "source": [
    "print(demo_instructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ec224c-5ca9-4c22-86fb-ece02369186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultatsF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaed9f0-351c-4710-8ea7-ede889f9bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = []\n",
    "for inst in range(30,100):\n",
    "    reponse = complete_and_print(demo_instructions[inst])\n",
    "    resultats.append(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4636365-3b08-4a70-86e1-3759ddded662",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultatsF = resultatsF + resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e3b10e-c9fb-4597-9901-2e9bcf7c50d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I'm trying to figure out how to extract the relation triplets from the given Text and Table. Let me start by understanding the problem step by step.\n",
      "\n",
      "First, I need to parse the CSV-like table. The table has the following columns: Company type, Industry, Founded, Founder, Headquarters, Products. The row under it is: Film production Film distribution | Entertainment | 1989 | G. Venkateswaran | Chennai, India | Motion pictures (Tamil). So, the table is about a company with those attributes.\n",
      "\n",
      "Next, I need to identify named entities from both the Text and the Table. From the Text, the entities I can spot are GV Films, Ishari K. Ganesh, G. Venkateswaran, Sujatha Films, Mani Ratnam, Manisha Koirala, Mahesh Manjrekar, Sanjay Dutt, Kasthuri Shankar, Urchagam, Kaivantha Kalai, Thirudi, Mumbai. From the Table, the entities are Film production Film distribution, Entertainment, 1989, G. Venkateswaran, Chennai, India, Motion pictures (Tamil). But wait, some of these are not named entities. For example, 1989 is a year, so not a named entity. Similarly, Chennai and India are locations, but they are named entities.\n",
      "\n",
      "Now, I need to generate cross-source pairs, meaning one entity from the Text and one from the Table. Let's list possible pairs:\n",
      "\n",
      "1. GV Films (Text) and Film production Film distribution (Table)\n",
      "2. GV Films and Entertainment\n",
      "3. GV Films and 1989 (not an entity, skip)\n",
      "4. GV Films and G. Venkateswaran (Table)\n",
      "5. GV Films and Chennai, India (Table)\n",
      "6. GV Films and Motion pictures (Tamil) (Table)\n",
      "7. Ishari K. Ganesh and Film production Film distribution\n",
      "8. Ishari K. Ganesh and Entertainment\n",
      "9. Ishari K. Ganesh and G. Venkateswaran\n",
      "10. Ishari K. Ganesh and Chennai, India\n",
      "11. Ishari K. Ganesh and Motion pictures (Tamil)\n",
      "12. G. Venkateswaran (Text) and Film production Film distribution\n",
      "13. G. Venkateswaran and Entertainment\n",
      "14. G. Venkateswaran and G. Venkateswaran (same entity, but from different sources)\n",
      "15. G. Venkateswaran and Chennai, India\n",
      "16. G. Venkateswaran and Motion pictures (Tamil)\n",
      "17. Sujatha Films and Film production Film distribution\n",
      "18. Sujatha Films and Entertainment\n",
      "19. Sujatha Films and G. Venkateswaran\n",
      "20. Sujatha Films and Chennai, India\n",
      "21. Sujatha Films and Motion pictures (Tamil)\n",
      "22. Mani Ratnam and Film production Film distribution\n",
      "23. Mani Ratnam and Entertainment\n",
      "24. Mani Ratnam and G. Venkateswaran\n",
      "25. Mani Ratnam and Chennai, India\n",
      "26. Mani Ratnam and Motion pictures (Tamil)\n",
      "27. Manisha Koirala and Film production Film distribution\n",
      "28. Manisha Koirala and Entertainment\n",
      "29. Manisha Koirala and G. Venkateswaran\n",
      "30. Manisha Koirala and Chennai, India\n",
      "31. Manisha Koirala and Motion pictures (Tamil)\n",
      "32. Mahesh Manjrekar and Film production Film distribution\n",
      "33. Mahesh Manjrekar and Entertainment\n",
      "34. Mahesh Manjrekar and G. Venkateswaran\n",
      "35. Mahesh Manjrekar and Chennai, India\n",
      "36. Mahesh Manjrekar and Motion pictures (Tamil)\n",
      "37. Sanjay Dutt and Film production Film distribution\n",
      "38. Sanjay Dutt and Entertainment\n",
      "39. Sanjay Dutt and G. Venkateswaran\n",
      "40. Sanjay Dutt and Chennai, India\n",
      "41. Sanjay Dutt and Motion pictures (Tamil)\n",
      "42. Kasthuri Shankar and Film production Film distribution\n",
      "43. Kasthuri Shankar and Entertainment\n",
      "44. Kasthuri Shankar and G. Venkateswaran\n",
      "45. Kasthuri Shankar and Chennai, India\n",
      "46. Kasthuri Shankar and Motion pictures (Tamil)\n",
      "47. Urchagam and Film production Film distribution\n",
      "48. Urchagam and Entertainment\n",
      "49. Urchagam and G. Venkateswaran\n",
      "50. Urchagam and Chennai, India\n",
      "51. Urchagam and Motion pictures (Tamil)\n",
      "52. Kaivantha Kalai and Film production Film distribution\n",
      "53. Kaivantha Kalai and Entertainment\n",
      "54. Kaivantha Kalai and G. Venkateswaran\n",
      "55. Kaivantha Kalai and Chennai, India\n",
      "56. Kaivantha Kalai and Motion pictures (Tamil)\n",
      "57. Thirudi and Film production Film distribution\n",
      "58. Thirudi and Entertainment\n",
      "59. Thirudi and G. Venkateswaran\n",
      "60. Thirudi and Chennai, India\n",
      "61. Thirudi and Motion pictures (Tamil)\n",
      "62. Mumbai and Film production Film distribution\n",
      "63. Mumbai and Entertainment\n",
      "64. Mumbai and G. Venkateswaran\n",
      "65. Mumbai and Chennai, India\n",
      "66. Mumbai and Motion pictures (Tamil)\n",
      "\n",
      "Now, I need to determine which of these pairs can form a valid triplet with one of the possible relations. The possible relations are: acquired_by, brand_of, client_of, collaboration, competitor_of, merged_with, product_or_service_of, regulated_by, shareholder_of, subsidiary_of, traded_on.\n",
      "\n",
      "Let me go through each pair and see if any relation is supported.\n",
      "\n",
      "Starting with GV Films (Text) and Film production Film distribution (Table). The Table's Company type is Film production Film distribution, and GV Films is a film production and distribution company. So, GV Films is the company, and Film production Film distribution is its type. The relation could be 'brand_of' or 'product_or_service_of'. But looking at the possible relations, 'product_or_service_of' seems appropriate because GV Films offers film production and distribution as their products/services.\n",
      "\n",
      "Next, GV Films and Entertainment (Industry). The industry is Entertainment, so GV Films operates in the Entertainment industry. The relation could be 'regulated_by' or 'product_or_service_of'. But 'regulated_by' doesn't fit here because Entertainment is the industry, not a regulator. 'Product_or_service_of' might not fit either. Alternatively, 'brand_of' could be considered, but it's not clear. Maybe no relation here.\n",
      "\n",
      "GV Films and G. Venkateswaran (Founder). G. Venkateswaran founded GV Films. So, the relation could be '-founder_of' but that's not in the possible relations. Alternatively, 'shareholder_of' or 'subsidiary_of' might not fit. So, perhaps no relation here.\n",
      "\n",
      "GV Films and Chennai, India (Headquarters). GV Films is headquartered in Chennai. The relation could be 'headquartered_in', but that's not in the possible relations. So, no relation.\n",
      "\n",
      "GV Films and Motion pictures (Tamil) (Products). GV Films produces motion pictures in Tamil. So, the relation could be 'product_or_service_of' because GV Films offers these motion pictures as their products.\n",
      "\n",
      "Moving on to Ishari K. Ganesh (Text) and Film production Film distribution (Table). Ishari heads GV Films, which is a film production and distribution company. So, similar to GV Films, the relation could be 'product_or_service_of'.\n",
      "\n",
      "Ishari K. Ganesh and Entertainment. He works in the Entertainment industry, so similar to GV Films, but no direct relation in the possible list.\n",
      "\n",
      "Ishari K. Ganesh and G. Venkateswaran. They are both associated with GV Films, but no direct relation in the possible list.\n",
      "\n",
      "Ishari K. Ganesh and Chennai, India. He is based there, but no relation in the list.\n",
      "\n",
      "Ishari K. Ganesh and Motion pictures (Tamil). He is involved in producing them, so 'product_or_service_of'.\n",
      "\n",
      "Next, G. Venkateswaran (Text) and Film production Film distribution (Table). He founded GV Films, which is a film production and distribution company. So, 'product_or_service_of' applies here as well.\n",
      "\n",
      "G. Venkateswaran and Entertainment. He is in the Entertainment industry, but no direct relation.\n",
      "\n",
      "G. Venkateswaran and G. Venkateswaran (same entity). Not useful.\n",
      "\n",
      "G. Venkateswaran and Chennai, India. He is based there, but no relation.\n",
      "\n",
      "G. Venkateswaran and Motion pictures (Tamil). He produces them, so 'product_or_service_of'.\n",
      "\n",
      "Sujatha Films (Text) and Film production Film distribution (Table). Sujatha Films is the former name of GV Films, which is a film production and distribution company. So, 'product_or_service_of'.\n",
      "\n",
      "Sujatha Films and Entertainment. Same as above, no direct relation.\n",
      "\n",
      "Sujatha Films and G. Venkateswaran. He founded Sujatha Films, but no direct relation in the list.\n",
      "\n",
      "Sujatha Films and Chennai, India. Based there, but no relation.\n",
      "\n",
      "Sujatha Films and Motion pictures (Tamil). They produce them, so 'product_or_service_of'.\n",
      "\n",
      "Mani Ratnam (Text) and Film production Film distribution. He worked with Sujatha Films, which is GV Films. So, 'product_or_service_of' as he contributed to their products.\n",
      "\n",
      "Mani Ratnam and Entertainment. Industry, no relation.\n",
      "\n",
      "Mani Ratnam and G. Venkateswaran. Collaborated, but 'collaboration' is a possible relation. So, Mani Ratnam and G. Venkateswaran: collaboration.\n",
      "\n",
      "Mani Ratnam and Chennai, India. Based there, no relation.\n",
      "\n",
      "Mani Ratnam and Motion pictures (Tamil). He worked on them, so 'product_or_service_of'.\n",
      "\n",
      "Manisha Koirala (Text) and Film production Film distribution. She was a board member, so 'product_or_service_of' as she was involved in their products.\n",
      "\n",
      "Manisha Koirala and Entertainment. Industry, no relation.\n",
      "\n",
      "Manisha Koirala and G. Venkateswaran. She was a board member, but no direct relation.\n",
      "\n",
      "Manisha Koirala and Chennai, India. Based there, no relation.\n",
      "\n",
      "Manisha Koirala and Motion pictures (Tamil). She was involved, so 'product_or_service_of'.\n",
      "\n",
      "Mahesh Manjrekar (Text) and Film production Film distribution. He directed a film for GV Films, so 'product_or_service_of'.\n",
      "\n",
      "Mahesh Manjrekar and Entertainment. Industry, no relation.\n",
      "\n",
      "Mahesh Manjrekar and G. Venkateswaran. Collaborated, so 'collaboration'.\n",
      "\n",
      "Mahesh Manjrekar and Chennai, India. Based there, no relation.\n",
      "\n",
      "Mahesh Manjrekar and Motion pictures (Tamil). He worked on them, so 'product_or_service_of'.\n",
      "\n",
      "Sanjay Dutt (Text) and Film production Film distribution. Starred in a film, so 'product_or_service_of'.\n",
      "\n",
      "Sanjay Dutt and Entertainment. Industry, no relation.\n",
      "\n",
      "Sanjay Dutt and G. Venkateswaran. Collaborated, so 'collaboration'.\n",
      "\n",
      "Sanjay Dutt and Chennai, India. Based there, no relation.\n",
      "\n",
      "Sanjay Dutt and Motion pictures (Tamil). He was in one, so 'product_or_service_of'.\n",
      "\n",
      "Kasthuri Shankar (Text) and Film production Film distribution. Worked with GV Films, so 'product_or_service_of'.\n",
      "\n",
      "Kasthuri Shankar and Entertainment. Industry, no relation.\n",
      "\n",
      "Kasthuri Shankar and G. Venkateswaran. Collaborated, so 'collaboration'.\n",
      "\n",
      "Kasthuri Shankar and Chennai, India. Based there, no relation.\n",
      "\n",
      "Kasthuri Shankar and Motion pictures (Tamil). Worked on them, so 'product_or_service_of'.\n",
      "\n",
      "Urchagam (Text) and Film production Film distribution. It's a film produced by GV Films, so 'product_or_service_of'.\n",
      "\n",
      "Urchagam and Entertainment. Industry, no relation.\n",
      "\n",
      "Urchagam and G. Venkateswaran. He produced it, so 'product_or_service_of'.\n",
      "\n",
      "Urchagam and Chennai, India. Produced there, no relation.\n",
      "\n",
      "Urchagam and Motion pictures (Tamil). It is one, so 'product_or_service_of'.\n",
      "\n",
      "Kaivantha Kalai (Text) and Film production Film distribution. Produced by GV Films, so 'product_or_service_of'.\n",
      "\n",
      "Kaivantha Kalai and Entertainment. Industry, no relation.\n",
      "\n",
      "Kaivantha Kalai and G. Venkateswaran. He produced it, so 'product_or_service_of'.\n",
      "\n",
      "Kaivantha Kalai and Chennai, India. Produced there, no relation.\n",
      "\n",
      "Kaivantha Kalai and Motion pictures (Tamil). It is one, so 'product_or_service_of'.\n",
      "\n",
      "Thirudi (Text) and Film production Film distribution. Produced by GV Films, so 'product_or_service_of'.\n",
      "\n",
      "Thirudi and Entertainment. Industry, no relation.\n",
      "\n",
      "Thirudi and G. Venkateswaran. He produced it, so 'product_or_service_of'.\n",
      "\n",
      "Thirudi and Chennai, India. Produced there, no relation.\n",
      "\n",
      "Thirudi and Motion pictures (Tamil). It is one, so 'product_or_service_of'.\n",
      "\n",
      "Mumbai (Text) and Film production Film distribution. GV Films held a ceremony in Mumbai, but no direct relation.\n",
      "\n",
      "Mumbai and Entertainment. Industry, no relation.\n",
      "\n",
      "Mumbai and G. Venkateswaran. No direct relation.\n",
      "\n",
      "Mumbai and Chennai, India. Both are locations, but no relation in the list.\n",
      "\n",
      "Mumbai and Motion pictures (Tamil). No direct relation.\n",
      "\n",
      "Now, compiling all the valid triplets:\n",
      "\n",
      "1. GV Films (Text) and Film production Film distribution (Table): product_or_service_of\n",
      "2. GV Films and Motion pictures (Tamil): product_or_service_of\n",
      "3. Ishari K. Ganesh and Film production Film distribution: product_or_service_of\n",
      "4. Ishari K. Ganesh and Motion pictures (Tamil): product_or_service_of\n",
      "5. G. Venkateswaran and Film production Film distribution: product_or_service_of\n",
      "6. G. Venkateswaran and Motion pictures (Tamil): product_or_service_of\n",
      "7. Sujatha Films and Film production Film distribution: product_or_service_of\n",
      "8. Sujatha Films and Motion pictures (Tamil): product_or_service_of\n",
      "9. Mani Ratnam and G. Venkateswaran: collaboration\n",
      "10. Mani Ratnam and Film production Film distribution: product_or_service_of\n",
      "11. Mani Ratnam and Motion pictures (Tamil): product_or_service_of\n",
      "12. Manisha Koirala and Film production Film distribution: product_or_service_of\n",
      "13. Manisha Koirala and Motion pictures (Tamil): product_or_service_of\n",
      "14. Mahesh Manjrekar and Film production Film distribution: product_or_service_of\n",
      "15. Mahesh Manjrekar and G. Venkateswaran: collaboration\n",
      "16. Mahesh Manjrekar and Motion pictures (Tamil): product_or_service_of\n",
      "17. Sanjay Dutt and Film production Film distribution: product_or_service_of\n",
      "18. Sanjay Dutt and G. Venkateswaran: collaboration\n",
      "19. Sanjay Dutt and Motion pictures (Tamil): product_or_service_of\n",
      "20. Kasthuri Shankar and Film production Film distribution: product_or_service_of\n",
      "21. Kasthuri Shankar and G. Venkateswaran: collaboration\n",
      "22. Kasthuri Shankar and Motion pictures (Tamil): product_or_service_of\n",
      "23. Urchagam and Film production Film distribution: product_or_service_of\n",
      "24. Urchagam and G. Venkateswaran: product_or_service_of\n",
      "25. Urchagam and Motion pictures (Tamil): product_or_service_of\n",
      "26. Kaivantha Kalai and Film production Film distribution: product_or_service_of\n",
      "27. Kaivantha Kalai and G. Venkateswaran: product_or_service_of\n",
      "28. Kaivantha Kalai and Motion pictures (Tamil): product_or_service_of\n",
      "29. Thirudi and Film production Film distribution: product_or_service_of\n",
      "30. Thirudi and G. Venkateswaran: product_or_service_of\n",
      "31. Thirudi and Motion pictures (Tamil): product_or_service_of\n",
      "\n",
      "Wait, but some of these might be duplicates or not correctly formatted. Also, I need to ensure that each triplet has one entity from Text and one from Table, and the relation is correctly applied.\n",
      "\n",
      "Looking back, for example, GV Films (Text) and Film production Film distribution (Table): product_or_service_of. That's correct because GV Films offers film production and distribution as their products/services.\n",
      "\n",
      "Similarly, GV Films and Motion pictures (Tamil): product_or_service_of because GV Films produces these motion pictures.\n",
      "\n",
      "Ishari K. Ganesh (Text) and Film production Film distribution (Table): product_or_service_of because he heads GV Films, which is a film production and distribution company.\n",
      "\n",
      "Ishari K. Ganesh and Motion pictures (Tamil): product_or_service_of as he is involved in producing them.\n",
      "\n",
      "G. Venkateswaran (Text) and Film production Film distribution (Table): product_or_service_of as he founded GV Films.\n",
      "\n",
      "G. Venkateswaran and Motion pictures (Tamil): product_or_service_of as he produces them.\n",
      "\n",
      "Sujatha Films (Text) and Film production Film distribution (Table): product_or_service_of as Sujatha Films is GV Films.\n",
      "\n",
      "Sujatha Films and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Mani Ratnam (Text) and G. Venkateswaran (Table): collaboration because they worked together on films.\n",
      "\n",
      "Mani Ratnam and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Mani Ratnam and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Manisha Koirala (Text) and Film production Film distribution: product_or_service_of as she was a board member.\n",
      "\n",
      "Manisha Koirala and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Mahesh Manjrekar (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Mahesh Manjrekar and G. Venkateswaran: collaboration as they worked on a film together.\n",
      "\n",
      "Mahesh Manjrekar and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Sanjay Dutt (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Sanjay Dutt and G. Venkateswaran: collaboration as he starred in a film produced by GV Films.\n",
      "\n",
      "Sanjay Dutt and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Kasthuri Shankar (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Kasthuri Shankar and G. Venkateswaran: collaboration as she worked with GV Films.\n",
      "\n",
      "Kasthuri Shankar and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Urchagam (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Urchagam and G. Venkateswaran: product_or_service_of as he produced it.\n",
      "\n",
      "Urchagam and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Kaivantha Kalai (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Kaivantha Kalai and G. Venkateswaran: product_or_service_of as he produced it.\n",
      "\n",
      "Kaivantha Kalai and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Thirudi (Text) and Film production Film distribution: product_or_service_of.\n",
      "\n",
      "Thirudi and G. Venkateswaran: product_or_service_of as he produced it.\n",
      "\n",
      "Thirudi and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Now, I need to format these triplets correctly, ensuring each has one entity from Text and one from Table, and the relation is correct.\n",
      "\n",
      "But wait, the Table's entity for products is \"Motion pictures (Tamil)\", so in triplets, it should be \"Motion pictures (Tamil)\".\n",
      "\n",
      "Also, some entities like Film production Film distribution are from the Table, so they should be treated as a single entity.\n",
      "\n",
      "So, the triplets would look like:\n",
      "\n",
      "GV Films, Film production Film distribution: product_or_service_of |\n",
      "GV Films, Motion pictures (Tamil): product_or_service_of |\n",
      "Ishari K. Ganesh, Film production Film distribution: product_or_service_of |\n",
      "Ishari K. Ganesh, Motion pictures (Tamil): product_or_service_of |\n",
      "G. Venkateswaran, Film production Film distribution: product_or_service_of |\n",
      "G. Venkateswaran, Motion pictures (Tamil): product_or_service_of |\n",
      "Sujatha Films, Film production Film distribution: product_or_service_of |\n",
      "Sujatha Films, Motion pictures (Tamil): product_or_service_of |\n",
      "Mani Ratnam, G. Venkateswaran: collaboration |\n",
      "Mani Ratnam, Film production Film distribution: product_or_service_of |\n",
      "Mani Ratnam, Motion pictures (Tamil): product_or_service_of |\n",
      "Manisha Koirala, Film production Film distribution: product_or_service_of |\n",
      "Manisha Koirala, Motion pictures (Tamil): product_or_service_of |\n",
      "Mahesh Manjrekar, Film production Film distribution: product_or_service_of |\n",
      "Mahesh Manjrekar, G. Venkateswaran: collaboration |\n",
      "Mahesh Manjrekar, Motion pictures (Tamil): product_or_service_of |\n",
      "Sanjay Dutt, Film production Film distribution: product_or_service_of |\n",
      "Sanjay Dutt, G. Venkateswaran: collaboration |\n",
      "Sanjay Dutt, Motion pictures (Tamil): product_or_service_of |\n",
      "Kasthuri Shankar, Film production Film distribution: product_or_service_of |\n",
      "Kasthuri Shankar, G. Venkateswaran: collaboration |\n",
      "Kasthuri Shankar, Motion pictures (Tamil): product_or_service_of |\n",
      "Urchagam, Film production Film distribution: product_or_service_of |\n",
      "Urchagam, G. Venkateswaran: product_or_service_of |\n",
      "Urchagam, Motion pictures (Tamil): product_or_service_of |\n",
      "Kaivantha Kalai, Film production Film distribution: product_or_service_of |\n",
      "Kaivantha Kalai, G. Venkateswaran: product_or_service_of |\n",
      "Kaivantha Kalai, Motion pictures (Tamil): product_or_service_of |\n",
      "Thirudi, Film production Film distribution: product_or_service_of |\n",
      "Thirudi, G. Venkateswaran: product_or_service_of |\n",
      "Thirudi, Motion pictures (Tamil): product_or_service_of\n",
      "\n",
      "But this seems like a lot of triplets. However, I need to ensure that each triplet is valid and doesn't repeat unnecessarily. Also, some might be redundant. For example, GV Films and Film production Film distribution: product_or_service_of is correct, but GV Films is the company, and Film production Film distribution is its type, so that's a valid triplet.\n",
      "\n",
      "Similarly, GV Films and Motion pictures (Tamil): product_or_service_of is correct because GV Films produces these motion pictures.\n",
      "\n",
      "Ishari K. Ganesh is the head of GV Films, so his relation to Film production Film distribution and Motion pictures (Tamil) is through GV Films, so those are valid.\n",
      "\n",
      "G. Venkateswaran is the founder, so his relations are similar.\n",
      "\n",
      "Sujatha Films is the former name, so same as GV Films.\n",
      "\n",
      "Mani Ratnam collaborated with G. Venkateswaran, so that's a collaboration relation.\n",
      "\n",
      "Similarly, Mahesh Manjrekar and Sanjay Dutt collaborated with G. Venkateswaran.\n",
      "\n",
      "Kasthuri Shankar also collaborated with him.\n",
      "\n",
      "The films Urchagam, Kaivantha Kalai, and Thirudi are products of GV Films, so they have product_or_service_of relations with Film production Film distribution and Motion pictures (Tamil), and also with G. Venkateswaran as the founder.\n",
      "\n",
      "So, all these triplets seem valid. However, the output format requires that each triplet is in the form entity1, entity2: relation, separated by |.\n",
      "\n",
      "But considering the possible relations, I think the main valid triplets are those where the Text entity is connected to the Table's products or company type.\n",
      "\n",
      "But to avoid redundancy, perhaps the main triplets are:\n",
      "\n",
      "GV Films, Film production Film distribution: product_or_service_of |\n",
      "GV Films, Motion pictures (Tamil): product_or_service_of |\n",
      "Sujatha Films, Film production Film distribution: product_or_service_of |\n",
      "Sujatha Films, Motion pictures (Tamil): product_or_service_of |\n",
      "Mani Ratnam, G. Venkateswaran: collaboration |\n",
      "Mahesh Manjrekar, G. Venkateswaran: collaboration |\n",
      "Sanjay Dutt, G. Venkateswaran: collaboration |\n",
      "Kasthuri Shankar, G. Venkateswaran: collaboration |\n",
      "Urchagam, Film production Film distribution: product_or_service_of |\n",
      "Urchagam, Motion pictures (Tamil): product_or_service_of |\n",
      "Kaivantha Kalai, Film production Film distribution: product_or_service_of |\n",
      "Kaivantha Kalai, Motion pictures (Tamil): product_or_service_of |\n",
      "Thirudi, Film production Film distribution: product_or_service_of |\n",
      "Thirudi, Motion pictures (Tamil): product_or_service_of\n",
      "\n",
      "But I'm not sure if all these are necessary. The example given in the problem had only one triplet, but in example 2, multiple triplets were output.\n",
      "\n",
      "So, perhaps the correct approach is to list all valid triplets without redundancy.\n",
      "\n",
      "But considering the time, I think the main triplet is GV Films and Film production Film distribution: product_or_service_of, and GV Films and Motion pictures (Tamil): product_or_service_of. Also, Sujatha Films and Film production Film distribution: product_or_service_of, and Sujatha Films and Motion pictures (Tamil): product_or_service_of.\n",
      "\n",
      "Additionally, the collaboration relations between Mani Ratnam, Mahesh Manjrekar, Sanjay Dutt, Kasthuri Shankar and G. Venkateswaran.\n",
      "\n",
      "And the films Urchagam, Kaivantha Kalai, Thirudi each have product_or_service_of relations with Film production Film distribution and Motion pictures (Tamil).\n",
      "\n",
      "So, compiling all these, the output would be a long string of triplets separated by |.\n",
      "\n",
      "But to ensure correctness, I'll list them all as per the above reasoning.\n",
      "</think>\n",
      "\n",
      "GV Films, Film production Film distribution: product_or_service_of | GV Films, Motion pictures (Tamil): product_or_service_of | Sujatha Films, Film production Film distribution: product_or_service_of | Sujatha Films, Motion pictures (Tamil): product_or_service_of | Mani Ratnam, G. Venkateswaran: collaboration | Mahesh Manjrekar, G. Venkateswaran: collaboration | Sanjay Dutt, G. Venkateswaran: collaboration | Kasthuri Shankar, G. Venkateswaran: collaboration | Urchagam, Film production Film distribution: product_or_service_of | Urchagam, Motion pictures (Tamil): product_or_service_of | Kaivantha Kalai, Film production Film distribution: product_or_service_of | Kaivantha Kalai, Motion pictures (Tamil): product_or_service_of | Thirudi, Film production Film distribution: product_or_service_of | Thirudi, Motion pictures (Tamil): product_or_service_of\n"
     ]
    }
   ],
   "source": [
    "print(resultatsF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9518dae-dbad-4054-83ab-486836a84e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultatsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b99a1eeb-225d-4af2-8e36-826f435109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_result = pd.read_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fb3017a-d020-4898-925f-4d9d98756b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_result= zero_shot_result[\"0\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "528d8034-1ab0-469d-a4ba-40361245a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_result = zero_shot_result + resultatsF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fa5e7-4e16-4662-b249-00c2ca270a00",
   "metadata": {},
   "source": [
    "## Preprocessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587e2ab-ecf1-42ab-b828-80b0424e48bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e03d11-93e9-4079-9bcb-84ff9fe49618",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = []\n",
    "for k, v in list(d.items()):\n",
    "    trilets_gold.append(v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541710b-205c-44a1-b0b2-7e8007f43124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c52388e8-e2aa-4995-b639-a8eee993f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    if not text.strip():  # cas vide\n",
    "        return triplets\n",
    "    \n",
    "    # split par \"|\" ou saut de ligne\n",
    "    parts = re.split(r\"\\||\\n\", text)\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        # format déjà \"entity1 ; entity2 ; relation\"\n",
    "        if \";\" in part:\n",
    "            elems = [p.strip() for p in part.split(\";\")]\n",
    "            if len(elems) == 3 and elems[1] in relations or elems[2] in relations:\n",
    "                # on doit détecter où se trouve la relation\n",
    "                if elems[1] in relations:\n",
    "                    triplets.append(f\"\"\"{elems[0].lower().replace(\" \",\"\")}; {elems[1].lower().replace(\" \",\"\")}; {elems[2].lower().replace(\" \",\"\")}\"\"\")\n",
    "                elif elems[2] in relations:\n",
    "                    triplets.append(f\"\"\"{elems[0].lower().replace(\" \",\"\")}; {elems[2].lower().replace(\" \",\"\")}; {elems[1].lower().replace(\" \",\"\")}\"\"\")\n",
    "            continue\n",
    "        \n",
    "        # format \"entity1, entity2: relation\"\n",
    "        m = re.match(r\"(.+?),\\s*(.+?):\\s*(\\w+)\", part)\n",
    "        if m:\n",
    "            e1, e2, rel = m.groups()\n",
    "            if rel in relations:\n",
    "                triplets.append(f\"\"\"{e1.strip().lower().replace(\" \",\"\")}; {rel.strip().lower().replace(\" \",\"\")}; {e2.strip().lower().replace(\" \",\"\")}\"\"\")\n",
    "    return triplets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "edff96c3-2013-4641-a63d-4edd6bdfca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_result = [extract_triplets(el) for el in zero_shot_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1b5e691-add7-4d9d-9955-4d12c656e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = [extract_triplets(el) for el in trilets_gold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8414de51-26c0-4cb1-8545-f3c365490773",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilets_gold = trilets_gold[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7de30f4-4dda-4f68-950d-50cbb31ae34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], ['tribunepublishing; subsidiary_of; spanfellermediagroup(smg)']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trilets_gold[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fcde3-8e46-46b3-9946-f2a7453b5433",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a00eda00-0e31-4251-a935-e53c20ef541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation_triplets import evaluation_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca5c8591-e24e-460f-9e9f-e8f63ae97c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluation_triplets(zero_shot_result[:5], trilets_gold[:5], relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8af99f5f-007a-4cac-b97f-866d944aebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Exact matching': {'precision': 0.0, 'recall': 0.0, 'f1': 0},\n",
       " 'Partial matching (head+tail)': {'precision': 0.0, 'recall': 0.0, 'f1': 0},\n",
       " 'Partial matching (relation + 1 entity)': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "580d6480-410f-4027-bf97-22fd82da5f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gvfilms; product_or_service_of; entertainment',\n",
       "  'gvfilms; product_or_service_of; motionpictures(tamil)',\n",
       "  'motionpictures(tamil); product_or_service_of; gvfilms'],\n",
       " ['spanfellermediagroup; subsidiary_of; tribunepublishing',\n",
       "  'tribunepublishing; acquired_by; spanfellermediagroup'],\n",
       " ['advansbanquecongo; subsidiary_of; advanssa',\n",
       "  'advansbanque; brand_of; advansbanquecongo',\n",
       "  'kfwentwicklungsbank; shareholder_of; advansbanquecongo',\n",
       "  'africandevelopmentbank; shareholder_of; advansbanquecongo',\n",
       "  'internationalfinancecorporation; shareholder_of; advansbanquecongo',\n",
       "  'horusdevelopmentfinance; shareholder_of; advansbanquecongo'],\n",
       " ['archipelagofilms; product_or_service_of; filmandtelevision',\n",
       "  'andrewyoung; collaboration; archipelagofilms',\n",
       "  'susantodd; collaboration; archipelagofilms'],\n",
       " ['seventhchannel; collaboration; starvijay',\n",
       "  'seventhchannel; product_or_service_of; mundhinampaartheney',\n",
       "  'seventhchannel; product_or_service_of; vithagan',\n",
       "  'magizhthirumeni; product_or_service_of; mundhinampaartheney',\n",
       "  'r.parthiban; product_or_service_of; vithagan',\n",
       "  'seventhchannel; product_or_service_of; mahabharat']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0df9e092-737a-4748-a39f-0bd7f2200900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['tribunepublishing; subsidiary_of; spanfellermediagroup(smg)'],\n",
       " [],\n",
       " [],\n",
       " ['maanbumigumaanavan; product_or_service_of; seventhchannel',\n",
       "  'seenu; product_or_service_of; seventhchannel',\n",
       "  'vettaiyaaduvilaiyaadu; product_or_service_of; seventhchannel',\n",
       "  'vithagan; product_or_service_of; seventhchannel',\n",
       "  'indiralohathilnaazhagappan; product_or_service_of; seventhchannel',\n",
       "  'mundhinampaartheney; product_or_service_of; seventhchannel',\n",
       "  'pudhiyathendral; product_or_service_of; seventhchannel',\n",
       "  'coolie; product_or_service_of; seventhchannel']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trilets_gold[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9d1ffd7-c241-4278-9397-a77beb843f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matching: {'precision': 0.11205976520811099, 'recall': 0.17781541066892464, 'f1': 0.13747954173486088}\n",
      "Partial matching (head+tail): {'precision': 0.3489861259338314, 'recall': 0.5537679932260796, 'f1': 0.42815057283142394}\n",
      "Partial matching (relation + 1 entity): {'precision': 0.29562433297758806, 'recall': 0.4690939881456393, 'f1': 0.3626841243862521}\n"
     ]
    }
   ],
   "source": [
    "def evaluation_triplets(pred, gold, relations_possibles):\n",
    "    import re\n",
    "\n",
    "    def normalize_entity(e):\n",
    "        \"\"\"Nettoie et met en minuscule pour comparaison plus souple\"\"\"\n",
    "        return re.sub(r'\\s+', '', e.lower())\n",
    "\n",
    "    def entities_equal(e1, e2):\n",
    "        \"\"\"Compare deux entités :\n",
    "        - identiques après normalisation\n",
    "        - OU si l’une est incluse dans l’autre\n",
    "        \"\"\"\n",
    "        e1, e2 = normalize_entity(e1), normalize_entity(e2)\n",
    "        return e1 == e2 or e1 in e2 or e2 in e1\n",
    "\n",
    "    def triples_equal(t1, t2):\n",
    "        \"\"\"Compare deux triplets :\n",
    "        - Exact (sujet + relation + objet)\n",
    "        - OU entités inversées avec même relation\n",
    "        \"\"\"\n",
    "        # (sujet, relation, objet)\n",
    "        h1, r1, t1_ = t1\n",
    "        h2, r2, t2_ = t2\n",
    "\n",
    "        if r1 != r2:\n",
    "            return False\n",
    "\n",
    "        # Cas 1 : correspondance directe\n",
    "        if entities_equal(h1, h2) and entities_equal(t1_, t2_):\n",
    "            return True\n",
    "        # Cas 2 : inversion des entités\n",
    "        if entities_equal(h1, t2_) and entities_equal(t1_, h2):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def entities_pair_equal(p1, p2):\n",
    "        \"\"\"Compare les paires d’entités (head, tail) :\n",
    "        - Exact\n",
    "        - OU inversées\n",
    "        - OU inclusives\n",
    "        \"\"\"\n",
    "        h1, t1_ = p1\n",
    "        h2, t2_ = p2\n",
    "\n",
    "        if entities_equal(h1, h2) and entities_equal(t1_, t2_):\n",
    "            return True\n",
    "        if entities_equal(h1, t2_) and entities_equal(t1_, h2):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    exact_tp = 0\n",
    "    partial_tp = 0\n",
    "    partial_rel_tp = 0\n",
    "    total_pred = 0\n",
    "    total_gold = 0\n",
    "\n",
    "    # Filtrage relations valides\n",
    "    pred = [\n",
    "        [p for p in pred_doc if p.split(';')[1].strip() in relations_possibles]\n",
    "        for pred_doc in pred\n",
    "    ]\n",
    "\n",
    "    for pred_doc, gold_doc in zip(pred, gold):\n",
    "        total_pred += len(pred_doc)\n",
    "        total_gold += len(gold_doc)\n",
    "\n",
    "        # Normalisation des triplets\n",
    "        pred_triples = []\n",
    "        for p in pred_doc:\n",
    "            p_parts = [part.strip() for part in p.split(';')]\n",
    "            if len(p_parts) == 3:\n",
    "                pred_triples.append(tuple(p_parts))\n",
    "\n",
    "        gold_triples = []\n",
    "        for g in gold_doc:\n",
    "            g_parts = [part.strip() for part in g.split(';')]\n",
    "            if len(g_parts) == 3:\n",
    "                gold_triples.append(tuple(g_parts))\n",
    "\n",
    "        # Exact matching\n",
    "        for p in pred_triples:\n",
    "            if any(triples_equal(p, g) for g in gold_triples):\n",
    "                exact_tp += 1\n",
    "\n",
    "        # Partial matching (head + tail seulement)\n",
    "        for p in pred_triples:\n",
    "            p_entities = (p[0], p[2])\n",
    "            if any(entities_pair_equal(p_entities, (g[0], g[2])) for g in gold_triples):\n",
    "                partial_tp += 1\n",
    "\n",
    "        # Partial match (relation correcte + une entité correcte)\n",
    "        for p in pred_triples:\n",
    "            for g in gold_triples:\n",
    "                if p[1] == g[1]:  # relation identique\n",
    "                    if entities_equal(p[0], g[0]) or entities_equal(p[2], g[2]) \\\n",
    "                       or entities_equal(p[0], g[2]) or entities_equal(p[2], g[0]):\n",
    "                        partial_rel_tp += 1\n",
    "                        break\n",
    "\n",
    "    # Métriques Exact\n",
    "    precision_exact = exact_tp / total_pred if total_pred > 0 else 0\n",
    "    recall_exact = exact_tp / total_gold if total_gold > 0 else 0\n",
    "    f1_exact = (2 * precision_exact * recall_exact) / (precision_exact + recall_exact) if (precision_exact + recall_exact) > 0 else 0\n",
    "\n",
    "    # Métriques Partial (head+tail)\n",
    "    precision_partial = partial_tp / total_pred if total_pred > 0 else 0\n",
    "    recall_partial = partial_tp / total_gold if total_gold > 0 else 0\n",
    "    f1_partial = (2 * precision_partial * recall_partial) / (precision_partial + recall_partial) if (precision_partial + recall_partial) > 0 else 0\n",
    "\n",
    "    # Métriques Partial (relation + une entité correcte)\n",
    "    precision_partial_rel = partial_rel_tp / total_pred if total_pred > 0 else 0\n",
    "    recall_partial_rel = partial_rel_tp / total_gold if total_gold > 0 else 0\n",
    "    f1_partial_rel = (2 * precision_partial_rel * recall_partial_rel) / (precision_partial_rel + recall_partial_rel) if (precision_partial_rel + recall_partial_rel) > 0 else 0\n",
    "\n",
    "    results = {\n",
    "        'Exact matching': {'precision': precision_exact, 'recall': recall_exact, 'f1': f1_exact},\n",
    "        'Partial matching (head+tail)': {'precision': precision_partial, 'recall': recall_partial, 'f1': f1_partial},\n",
    "        'Partial matching (relation + 1 entity)': {'precision': precision_partial_rel, 'recall': recall_partial_rel, 'f1': f1_partial_rel}\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "# Exemple d’utilisation\n",
    "\n",
    "relations_possibles = ['acquired_by', 'brand_of', 'client_of', 'collaboration', 'merged_with',\n",
    "                       'product_or_service_of', 'shareholder_of', 'subsidiary_of', 'traded_on']\n",
    "\n",
    "results = evaluation_triplets(zero_shot_result, trilets_gold, relations_possibles)\n",
    "for task in results:\n",
    "    print(f\"{task}: {results[task]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b6e62-ec93-4bb3-9596-f1008ec3e099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
