{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78eeb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a70b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175da933",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e2f1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the CoNLL-2003 formatted dataset\n",
    "\n",
    "ent_dict = {\n",
    "    'PER': 'person',\n",
    "    'ORG': 'organization',\n",
    "    'LOC': 'location',\n",
    "}\n",
    "\n",
    "def read_conll_file(file_path):\n",
    "    sentences, tokens, labels = [], [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if line.strip() == '':\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                parts = line.strip().split()\n",
    "                token, label = parts[0], parts[-1]\n",
    "                tokens.append(token)\n",
    "                labels.append(label)\n",
    "                sentence.append((token, label))\n",
    "                \n",
    "    return sentences\n",
    "                \n",
    "\n",
    "def get_ner_dataset(sentences):\n",
    "    \n",
    "    inputs, outputs, instructions = [], [], []\n",
    "    count = {'person': 0, 'organization': 0, 'location': 0}\n",
    "    for sentence in sentences:\n",
    "        is_entity = [tup[1] != 'O' and not tup[1].endswith('MISC') for tup in sentence]\n",
    "        if sum(is_entity) == 0:\n",
    "            continue\n",
    "        instructions.append('Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.')\n",
    "        inputs.append(' '.join([tup[0] for tup in sentence]))\n",
    "        outputs.append('')\n",
    "        tmp_tup_list = []\n",
    "        for i, tup in enumerate(sentence):\n",
    "            if tmp_tup_list and (not is_entity[i] or tmp_tup_list[-1][1] != tup[1] or i + 1 == len(sentence)):\n",
    "                entity = ' '.join([t[0] for t in tmp_tup_list])\n",
    "                assert tmp_tup_list[0][1] == tmp_tup_list[-1][1], tmp_tup_list\n",
    "                entity_type = ent_dict[tmp_tup_list[-1][1].split('-')[-1]]\n",
    "                a = 'an' if entity_type == 'organization' else 'a'\n",
    "                outputs[-1] += f'{entity} is {a} {entity_type}, ' \n",
    "                tmp_tup_list = [] if not is_entity[i] else [tup]\n",
    "                count[entity_type] += 1\n",
    "            elif is_entity[i]:\n",
    "                tmp_tup_list.append(tup)\n",
    "            else:\n",
    "                pass\n",
    "        outputs[-1] = outputs[-1].strip(', ') + '.'\n",
    "    \n",
    "    print(len(instructions))\n",
    "    print(count)\n",
    "        \n",
    "    return {\"input\": inputs, \"output\": outputs, \"instruction\": instructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b136afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "{'person': 745, 'organization': 243, 'location': 168}\n",
      "98\n",
      "{'person': 216, 'organization': 56, 'location': 39}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00464177131652832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 511,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de323eafdf649b8af9b322dc33d0fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/511 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004297494888305664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 98,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f28cf02724a729c9421e7b29349c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 511\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_conll_file('./SEC-filings/CONLL-format/data/train/FIN5.txt')\n",
    "test_data = read_conll_file('./SEC-filings/CONLL-format/data/test/FIN3.txt')\n",
    "\n",
    "train_data = get_ner_dataset(train_data)\n",
    "test_data = get_ner_dataset(test_data)\n",
    "\n",
    "ner_dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict(train_data),\n",
    "    'test': Dataset.from_dict(test_data)\n",
    "})\n",
    "ner_dataset.save_to_disk('fingpt-ner')\n",
    "ner_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e8a1b",
   "metadata": {},
   "source": [
    "# FinRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92b92f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FinRED/relations.txt') as f:\n",
    "    relations = [r.strip() for r in f.readlines()]\n",
    "\n",
    "    \n",
    "def get_instruction(sent, tuples, with_orig=True, with_cls=False):\n",
    "    \n",
    "    instructions, inputs, outputs = [], [], []\n",
    "    if with_orig:\n",
    "        instructions.append(f\"Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be \\\"relation1: word1, word2; relation2: word3, word4\\\". Options: {', '.join(relations)}.\")\n",
    "        instructions.append(f\"Given the input sentence, please extract the subject and object containing a certain relation in the sentence according to the following relation types, in the format of \\\"relation1: word1, word2; relation2: word3, word4\\\". Relations include: {'; '.join(relations)}.\")\n",
    "        inputs.extend([sent] * 2)\n",
    "        outputs.extend([\"; \".join([f\"{tup[-1]}: {tup[0]}, {tup[1]}\" for tup in tuples])] * 2)\n",
    "    \n",
    "    if with_cls:\n",
    "        for tup in tuples:\n",
    "            instructions.append(f\"Utilize the input text as a context reference, choose the right relationship between {tup[0]} and {tup[1]} from the options. Options: {', '.join(relations)}.\")\n",
    "            instructions.append(f\"What is the relationship between {tup[0]} and {tup[1]} in the context of the input sentence. Choose an answer from: {'; '.join(relations)}.\")\n",
    "            inputs.extend([sent] * 2)\n",
    "            outputs.extend([tup[-1]] * 2)\n",
    "    \n",
    "    return instructions, inputs, outputs\n",
    "\n",
    "\n",
    "def get_finred_dataset(sent_file, tup_file, with_orig, with_cls):\n",
    "\n",
    "    instructions, inputs, outputs = [], [], []\n",
    "\n",
    "    with open(sent_file) as f:\n",
    "        sentences = [s.strip() for s in f.readlines()]\n",
    "    with open(tup_file) as f:\n",
    "        tuples_list = [s.split(' | ') for s in f.readlines()]\n",
    "        \n",
    "    for sent, tuples in zip(sentences, tuples_list):\n",
    "        tuples = [[e.strip() for e in tup.split(' ; ')] for tup in tuples]\n",
    "        \n",
    "        ins, i, o = get_instruction(sent, tuples, with_orig, with_cls)\n",
    "        \n",
    "        instructions.extend(ins)\n",
    "        inputs.extend(i)\n",
    "        outputs.extend(o)\n",
    "        \n",
    "    return Dataset.from_dict({\n",
    "        'input': inputs,\n",
    "        'output': outputs,\n",
    "        'instruction': instructions\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75783f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0045130252838134766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 27558,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/27558 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004259586334228516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 5112,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5112 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 27558\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 5112\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_finred_dataset('FinRED/train.sent', 'FinRED/train.tup', with_orig=True, with_cls=True)\n",
    "test_dataset = get_finred_dataset('FinRED/test.sent', 'FinRED/test.tup', with_orig=True, with_cls=True)\n",
    "\n",
    "finred_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "finred_dataset.save_to_disk('fingpt-finred')\n",
    "finred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e462138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_finred_dataset('FinRED/train.sent', 'FinRED/train.tup', with_orig=True, with_cls=False)\n",
    "test_dataset = get_finred_dataset('FinRED/test.sent', 'FinRED/test.tup', with_orig=True, with_cls=False)\n",
    "\n",
    "finred_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "finred_dataset.save_to_disk('fingpt-finred-re')\n",
    "finred_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1ae42",
   "metadata": {},
   "source": [
    "# Prepare my data finRED\n",
    "## Jointly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e77586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1f5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocess_text(text):\n",
    "    processed_words = []\n",
    "    text = text.replace('\\n', '.')\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = text.replace(\"\\\\xa\",\" \")\n",
    "    text = re.sub(r'\\[.*?\\]', ' ', text)\n",
    "    text = re.sub(r'\\/.*?\\/', ' ', text)\n",
    "    text = text.replace('\\\\', '')\n",
    "    text = ' '.join(re.findall(r'\\w+', text))\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if not token.is_space and not token.is_punct:\n",
    "            lemma = token.lemma_\n",
    "            if len(lemma)>1:\n",
    "                processed_words.append(lemma.lower())\n",
    "    processed_text = ' '.join(processed_words)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c74f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a097b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>relation</th>\n",
       "      <th>org</th>\n",
       "      <th>actor1</th>\n",
       "      <th>s1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>s2</th>\n",
       "      <th>token</th>\n",
       "      <th>subj_start</th>\n",
       "      <th>subj_end</th>\n",
       "      <th>obj_start</th>\n",
       "      <th>obj_end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Video : [E11] Thales [E12] , [E21] Intelsat [E...</td>\n",
       "      <td>0</td>\n",
       "      <td>Video : # ORG # , $ ORG $ , Bombardier , Etiha...</td>\n",
       "      <td>Thales Group</td>\n",
       "      <td>3.396017</td>\n",
       "      <td>Intelsat</td>\n",
       "      <td>11.427920</td>\n",
       "      <td>['Video', ':', 'Thales', ',', 'Intelsat', ',',...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the fuselage , [E11] Boeing [E12] has taken...</td>\n",
       "      <td>0</td>\n",
       "      <td>On the fuselage , # ORG # has taken advantage ...</td>\n",
       "      <td>Boeing</td>\n",
       "      <td>11.025807</td>\n",
       "      <td>Beechcraft Premier I</td>\n",
       "      <td>0.102741</td>\n",
       "      <td>['On', 'the', 'fuselage', ',', 'Boeing', 'has'...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[E11] NASA [E12] , New Stability , Samsung , ...</td>\n",
       "      <td>0</td>\n",
       "      <td># ORG # , New Stability , Samsung , Goal , Se...</td>\n",
       "      <td>NASA</td>\n",
       "      <td>7.224445</td>\n",
       "      <td>Volvo Cars</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>['NASA', ',', 'New', 'Stability', ',', 'Samsun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[E11] Thales [E12] s primary competitors are ...</td>\n",
       "      <td>3</td>\n",
       "      <td># ORG # s primary competitors are $ ORG $ , S...</td>\n",
       "      <td>Thales Group</td>\n",
       "      <td>3.755883</td>\n",
       "      <td>Rockwell Collins</td>\n",
       "      <td>11.022833</td>\n",
       "      <td>['Thales', 's', 'primary', 'competitors', 'are...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The traditional large pharmaceutical and consu...</td>\n",
       "      <td>0</td>\n",
       "      <td>The traditional large pharmaceutical and consu...</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>10.955735</td>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>12.113450</td>\n",
       "      <td>['The', 'traditional', 'large', 'pharmaceutica...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  relation  \\\n",
       "0  Video : [E11] Thales [E12] , [E21] Intelsat [E...         0   \n",
       "1  On the fuselage , [E11] Boeing [E12] has taken...         0   \n",
       "2   [E11] NASA [E12] , New Stability , Samsung , ...         0   \n",
       "3   [E11] Thales [E12] s primary competitors are ...         3   \n",
       "4  The traditional large pharmaceutical and consu...         0   \n",
       "\n",
       "                                                 org        actor1         s1  \\\n",
       "0  Video : # ORG # , $ ORG $ , Bombardier , Etiha...  Thales Group   3.396017   \n",
       "1  On the fuselage , # ORG # has taken advantage ...        Boeing  11.025807   \n",
       "2   # ORG # , New Stability , Samsung , Goal , Se...          NASA   7.224445   \n",
       "3   # ORG # s primary competitors are $ ORG $ , S...  Thales Group   3.755883   \n",
       "4  The traditional large pharmaceutical and consu...         Bayer  10.955735   \n",
       "\n",
       "                 actor2         s2  \\\n",
       "0              Intelsat  11.427920   \n",
       "1  Beechcraft Premier I   0.102741   \n",
       "2            Volvo Cars   0.005962   \n",
       "3      Rockwell Collins  11.022833   \n",
       "4       GlaxoSmithKline  12.113450   \n",
       "\n",
       "                                               token  subj_start  subj_end  \\\n",
       "0  ['Video', ':', 'Thales', ',', 'Intelsat', ',',...           2         2   \n",
       "1  ['On', 'the', 'fuselage', ',', 'Boeing', 'has'...           4         4   \n",
       "2  ['NASA', ',', 'New', 'Stability', ',', 'Samsun...           0         0   \n",
       "3  ['Thales', 's', 'primary', 'competitors', 'are...           0         0   \n",
       "4  ['The', 'traditional', 'large', 'pharmaceutica...          22        22   \n",
       "\n",
       "   obj_start  obj_end        label  \n",
       "0          4        4     negative  \n",
       "1         20       20     negative  \n",
       "2         12       12     negative  \n",
       "3          5        6  Competition  \n",
       "4         24       24     negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainb = pd.read_csv(\"/users/melodi/mettaleb/ECLADATA/BizRel-Hadjer/Bert_re_Hadjer/data/bizrel/train_bizrel_luke.tsv\", sep='\\t') \n",
    "testb = pd.read_csv(\"/users/melodi/mettaleb/ECLADATA/BizRel-Hadjer/Bert_re_Hadjer/data/bizrel/test_bizrel_luke.tsv\", sep='\\t') \n",
    "devb =  pd.read_csv(\"/users/melodi/mettaleb/ECLADATA/BizRel-Hadjer/Bert_re_Hadjer/data/bizrel/dev_bizrel_luke.tsv\", sep='\\t')\n",
    "df = pd.concat([trainb,devb,testb])\n",
    "mapping = {\n",
    "    0: 'negative',\n",
    "    1: 'Investment',\n",
    "    2: 'Sale-Purchase',\n",
    "    3: 'Competition',\n",
    "    4: 'Partnership',\n",
    "    5: 'Legal-proceeding'}\n",
    "\n",
    "df['label'] = df['relation'].map(mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248e670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacer_balises(phrase):\n",
    "    phrase = phrase.replace(\"[E11]\", \"\").replace(\"[E12]\", \"\").replace(\"[E21]\", \"\").replace(\"[E22]\", \"\")\n",
    "    return preprocess_text(phrase)\n",
    "def remplacer_actor1(phrase):\n",
    "    actor1 = phrase.split(\"[E11]\")[1].split(\"[E12]\")[0].strip()\n",
    "    return preprocess_text(actor1)\n",
    "def remplacer_actor2(phrase):\n",
    "    actor2 = phrase.split(\"[E21]\")[1].split(\"[E22]\")[0].strip()\n",
    "    return preprocess_text(actor2)\n",
    "\n",
    "\n",
    "\n",
    "# Appliquer la fonction à la colonne \"texte\"\n",
    "df[\"actor1\"] = df[\"sentence\"].apply(remplacer_actor1)\n",
    "df[\"actor2\"] = df[\"sentence\"].apply(remplacer_actor2)\n",
    "df[\"text\"] = df[\"sentence\"].apply(remplacer_balises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286d2199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>relation</th>\n",
       "      <th>org</th>\n",
       "      <th>actor1</th>\n",
       "      <th>s1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>s2</th>\n",
       "      <th>token</th>\n",
       "      <th>subj_start</th>\n",
       "      <th>subj_end</th>\n",
       "      <th>obj_start</th>\n",
       "      <th>obj_end</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Video : [E11] Thales [E12] , [E21] Intelsat [E...</td>\n",
       "      <td>0</td>\n",
       "      <td>Video : # ORG # , $ ORG $ , Bombardier , Etiha...</td>\n",
       "      <td>thale</td>\n",
       "      <td>3.396017</td>\n",
       "      <td>intelsat</td>\n",
       "      <td>11.427920</td>\n",
       "      <td>['Video', ':', 'Thales', ',', 'Intelsat', ',',...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>video thales intelsat bombardier etihad hmgaer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the fuselage , [E11] Boeing [E12] has taken...</td>\n",
       "      <td>0</td>\n",
       "      <td>On the fuselage , # ORG # has taken advantage ...</td>\n",
       "      <td>boeing</td>\n",
       "      <td>11.025807</td>\n",
       "      <td>premier</td>\n",
       "      <td>0.102741</td>\n",
       "      <td>['On', 'the', 'fuselage', ',', 'Boeing', 'has'...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>negative</td>\n",
       "      <td>on the fuselage boeing have take advantage of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[E11] NASA [E12] , New Stability , Samsung , ...</td>\n",
       "      <td>0</td>\n",
       "      <td># ORG # , New Stability , Samsung , Goal , Se...</td>\n",
       "      <td>nasa</td>\n",
       "      <td>7.224445</td>\n",
       "      <td>volvo</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>['NASA', ',', 'New', 'Stability', ',', 'Samsun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>negative</td>\n",
       "      <td>nasa new stability samsung goal seen physique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[E11] Thales [E12] s primary competitors are ...</td>\n",
       "      <td>3</td>\n",
       "      <td># ORG # s primary competitors are $ ORG $ , S...</td>\n",
       "      <td>thale</td>\n",
       "      <td>3.755883</td>\n",
       "      <td>rockwell collins</td>\n",
       "      <td>11.022833</td>\n",
       "      <td>['Thales', 's', 'primary', 'competitors', 'are...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Competition</td>\n",
       "      <td>thale primary competitor be rockwell collins s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The traditional large pharmaceutical and consu...</td>\n",
       "      <td>0</td>\n",
       "      <td>The traditional large pharmaceutical and consu...</td>\n",
       "      <td>bayer</td>\n",
       "      <td>10.955735</td>\n",
       "      <td>glaxosmithkline</td>\n",
       "      <td>12.113450</td>\n",
       "      <td>['The', 'traditional', 'large', 'pharmaceutica...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>negative</td>\n",
       "      <td>the traditional large pharmaceutical and consu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  relation  \\\n",
       "0  Video : [E11] Thales [E12] , [E21] Intelsat [E...         0   \n",
       "1  On the fuselage , [E11] Boeing [E12] has taken...         0   \n",
       "2   [E11] NASA [E12] , New Stability , Samsung , ...         0   \n",
       "3   [E11] Thales [E12] s primary competitors are ...         3   \n",
       "4  The traditional large pharmaceutical and consu...         0   \n",
       "\n",
       "                                                 org  actor1         s1  \\\n",
       "0  Video : # ORG # , $ ORG $ , Bombardier , Etiha...   thale   3.396017   \n",
       "1  On the fuselage , # ORG # has taken advantage ...  boeing  11.025807   \n",
       "2   # ORG # , New Stability , Samsung , Goal , Se...    nasa   7.224445   \n",
       "3   # ORG # s primary competitors are $ ORG $ , S...   thale   3.755883   \n",
       "4  The traditional large pharmaceutical and consu...   bayer  10.955735   \n",
       "\n",
       "             actor2         s2  \\\n",
       "0          intelsat  11.427920   \n",
       "1           premier   0.102741   \n",
       "2             volvo   0.005962   \n",
       "3  rockwell collins  11.022833   \n",
       "4   glaxosmithkline  12.113450   \n",
       "\n",
       "                                               token  subj_start  subj_end  \\\n",
       "0  ['Video', ':', 'Thales', ',', 'Intelsat', ',',...           2         2   \n",
       "1  ['On', 'the', 'fuselage', ',', 'Boeing', 'has'...           4         4   \n",
       "2  ['NASA', ',', 'New', 'Stability', ',', 'Samsun...           0         0   \n",
       "3  ['Thales', 's', 'primary', 'competitors', 'are...           0         0   \n",
       "4  ['The', 'traditional', 'large', 'pharmaceutica...          22        22   \n",
       "\n",
       "   obj_start  obj_end        label  \\\n",
       "0          4        4     negative   \n",
       "1         20       20     negative   \n",
       "2         12       12     negative   \n",
       "3          5        6  Competition   \n",
       "4         24       24     negative   \n",
       "\n",
       "                                                text  \n",
       "0  video thales intelsat bombardier etihad hmgaer...  \n",
       "1  on the fuselage boeing have take advantage of ...  \n",
       "2  nasa new stability samsung goal seen physique ...  \n",
       "3  thale primary competitor be rockwell collins s...  \n",
       "4  the traditional large pharmaceutical and consu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1499a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans l'ensemble d'entraînement :\n",
      " negative            1328\n",
      "Competition          394\n",
      "Partnership          148\n",
      "Investment            66\n",
      "Sale-Purchase         58\n",
      "Legal-proceeding      12\n",
      "Name: label, dtype: int64\n",
      "Distribution des classes dans l'ensemble de test :\n",
      " negative            5316\n",
      "Competition         1577\n",
      "Partnership          590\n",
      "Investment           265\n",
      "Sale-Purchase        234\n",
      "Legal-proceeding      46\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df[[\"text\",\"actor1\",\"actor2\",\"label\"]], test_size=0.8, stratify=df['label'], random_state=42)\n",
    "\n",
    "print(\"Distribution des classes dans l'ensemble d'entraînement :\\n\", train_df['label'].value_counts())\n",
    "print(\"Distribution des classes dans l'ensemble de test :\\n\", test_df['label'].value_counts())\n",
    "\n",
    "\n",
    "#train_df.to_csv('trainBizRel.csv', index=False)\n",
    "#test_df.to_csv('testBizRel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5349c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_entiers_aleatoires(n):\n",
    "    liste_entiers = []\n",
    "    for _ in range(n):\n",
    "        entier = random.randint(0, n // 2)\n",
    "        liste_entiers.append(entier)\n",
    "    return liste_entiers\n",
    "l=test_df['text'].to_list()\n",
    "with open(\"test.sent\", \"w\") as fsent, open(\"test.dep\", \"w\") as fichier:\n",
    "    for sentence in l:\n",
    "        sentence = sentence.strip()\n",
    "        #sentence = preprocess_text(sentence)\n",
    "        fsent.write(sentence+\"\\n\")\n",
    "        n = len(sentence.split())\n",
    "        resultat = generer_entiers_aleatoires(n)\n",
    "        data = '{{\"adj_mat\": [{}]}}\\n'.format(resultat)\n",
    "        fichier.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d3e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'negative':\"undefined\",\n",
    "    'Investment':\"shareholder_of\",\n",
    "    'Sale-Purchase':\"mergedwith\",\n",
    "    'Competition':\"competitor_of\",\n",
    "    'Partnership':\"collaboration\",\n",
    "    'Legal-proceeding':\"undefined\"}\n",
    "test_df['label_core'] = test_df['label'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e537c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_core</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>major player operate in the global artificial ...</td>\n",
       "      <td>icarbonx</td>\n",
       "      <td>intel</td>\n",
       "      <td>Competition</td>\n",
       "      <td>competitor_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>consumer package good cpg company take part in...</td>\n",
       "      <td>nestle</td>\n",
       "      <td>clorox</td>\n",
       "      <td>negative</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>he have represent various bank include us exim...</td>\n",
       "      <td>bank of nova scotia</td>\n",
       "      <td>barclay</td>\n",
       "      <td>negative</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>aldi sam club costco kroger whole foods ahold ...</td>\n",
       "      <td>costco</td>\n",
       "      <td>publix</td>\n",
       "      <td>negative</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>it also include airplane manufacturer airbus s...</td>\n",
       "      <td>safran</td>\n",
       "      <td>sony</td>\n",
       "      <td>negative</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text               actor1  \\\n",
       "747   major player operate in the global artificial ...             icarbonx   \n",
       "2001  consumer package good cpg company take part in...               nestle   \n",
       "1617  he have represent various bank include us exim...  bank of nova scotia   \n",
       "334   aldi sam club costco kroger whole foods ahold ...               costco   \n",
       "794   it also include airplane manufacturer airbus s...               safran   \n",
       "\n",
       "       actor2        label     label_core  \n",
       "747     intel  Competition  competitor_of  \n",
       "2001   clorox     negative      undefined  \n",
       "1617  barclay     negative      undefined  \n",
       "334    publix     negative      undefined  \n",
       "794      sony     negative      undefined  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b29706",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_actor1 = test_df['actor1'].to_list()\n",
    "l_actor2 = test_df['actor2'].to_list()\n",
    "l_relation = test_df['label'].to_list()\n",
    "with open(\"test.tup\", \"w\") as file:\n",
    "    for i in range(len(l_actor1)):\n",
    "        file.write(f\"{l_actor1[i]} ; {l_actor2[i]} ; {l_relation[i]}\\n\")\n",
    "        #file.write(f\"{l_relation[i].strip()}\\n\")\n",
    "\n",
    "l=train_df['text'].to_list()\n",
    "l_actor1 = train_df['actor1'].to_list()\n",
    "l_actor2 = train_df['actor2'].to_list()\n",
    "l_relation = train_df['label'].to_list()\n",
    "with open(\"train.tup\", \"w\") as file:\n",
    "    for i in range(len(l_actor1)):\n",
    "        file.write(f\"{l_actor1[i]} ; {l_actor2[i]} ; {l_relation[i]}\\n\")\n",
    "        #file.write(f\"{l_relation[i].strip()}\\n\")\n",
    "with open(\"train.sent\", \"w\") as fsent:\n",
    "    for sentence in l:\n",
    "        sentence = sentence.strip()\n",
    "        fsent.write(sentence+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c7d50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Competition',\n",
       " 'Investment',\n",
       " 'Legal-proceeding',\n",
       " 'Partnership',\n",
       " 'Sale-Purchase',\n",
       " 'negative'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391d1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>700 organization include 20th century fox jetb...</td>\n",
       "      <td>jetblue</td>\n",
       "      <td>nordstrom</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>stantec trade on the tsx and the nyse under th...</td>\n",
       "      <td>stantec</td>\n",
       "      <td>tsx</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>other global company envision this new form of...</td>\n",
       "      <td>volkswagen group</td>\n",
       "      <td>geely automobile holdings</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>2018 first championship lead sponsor include g...</td>\n",
       "      <td>google</td>\n",
       "      <td>magna international</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>well establish company such as procter gamble ...</td>\n",
       "      <td>johnson johnson</td>\n",
       "      <td>philip morris international</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            actor1  \\\n",
       "4562  700 organization include 20th century fox jetb...           jetblue   \n",
       "4362  stantec trade on the tsx and the nyse under th...           stantec   \n",
       "6804  other global company envision this new form of...  volkswagen group   \n",
       "6848  2018 first championship lead sponsor include g...            google   \n",
       "5645  well establish company such as procter gamble ...   johnson johnson   \n",
       "\n",
       "                           actor2     label  \n",
       "4562                    nordstrom  negative  \n",
       "4362                          tsx  negative  \n",
       "6804    geely automobile holdings  negative  \n",
       "6848          magna international  negative  \n",
       "5645  philip morris international  negative  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c26a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_ = {'Competition',\n",
    " 'Investment',\n",
    " 'Legal-proceeding',\n",
    " 'Partnership',\n",
    " 'Sale-Purchase',\n",
    " 'negative'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c265a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relations_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#with open('mydata/relations.txt') as f:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#    relations = [r.strip() for r in f.readlines()]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m relations\u001b[38;5;241m=\u001b[39m[r\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrelations_\u001b[49m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_instruction\u001b[39m(sent, tuples, with_orig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, with_cls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m     instructions, inputs, outputs \u001b[38;5;241m=\u001b[39m [], [], []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'relations_' is not defined"
     ]
    }
   ],
   "source": [
    "#with open('mydata/relations.txt') as f:\n",
    "#    relations = [r.strip() for r in f.readlines()]\n",
    "relations=[r.strip() for r in relations_]\n",
    "    \n",
    "def get_instruction(sent, tuples, with_orig=True, with_cls=False):\n",
    "    \n",
    "    instructions, inputs, outputs = [], [], []\n",
    "    if with_orig:\n",
    "        instructions.append(f\"Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be \\\"relation1: word1, word2; relation2: word3, word4\\\". Options: {', '.join(relations)}.\")\n",
    "        instructions.append(f\"Given the input sentence, please extract the subject and object containing a certain relation in the sentence according to the following relation types, in the format of \\\"relation1: word1, word2; relation2: word3, word4\\\". Relations include: {'; '.join(relations)}.\")\n",
    "        inputs.extend([sent] * 2)\n",
    "        outputs.extend([\"; \".join([f\"{tup[-1]}: {tup[0]}, {tup[1]}\" for tup in tuples])] * 2)\n",
    "    \n",
    "    if with_cls:\n",
    "        for tup in tuples:\n",
    "            instructions.append(f\"Utilize the input text as a context reference, choose the right relationship between {tup[0]} and {tup[1]} from the options. Options: {', '.join(relations)}.\")\n",
    "            instructions.append(f\"What is the relationship between {tup[0]} and {tup[1]} in the context of the input sentence. Choose an answer from: {'; '.join(relations)}.\")\n",
    "            inputs.extend([sent] * 2)\n",
    "            outputs.extend([tup[-1]] * 2)\n",
    "            #inputs.extend([sent])\n",
    "            #outputs.extend([tup[-1]])\n",
    "    \n",
    "    return instructions, inputs, outputs\n",
    "\n",
    "\n",
    "def get_finred_dataset(sent_file, tup_file, with_orig, with_cls):\n",
    "\n",
    "    instructions, inputs, outputs = [], [], []\n",
    "\n",
    "    with open(sent_file) as f:\n",
    "        sentences = [s.strip() for s in f.readlines()]\n",
    "    with open(tup_file) as f:\n",
    "        tuples_list = [s.split(' | ') for s in f.readlines()]\n",
    "        \n",
    "    for sent, tuples in zip(sentences, tuples_list):\n",
    "        tuples = [[e.strip() for e in tup.split(' ; ')] for tup in tuples]\n",
    "        \n",
    "        ins, i, o = get_instruction(sent, tuples, with_orig, with_cls)\n",
    "        \n",
    "        instructions.extend(ins)\n",
    "        inputs.extend(i)\n",
    "        outputs.extend(o)\n",
    "    print(\"longuer = \",len(outputs))\n",
    "    print(\"exemple : \",outputs[:10])\n",
    "        \n",
    "    return Dataset.from_dict({\n",
    "        'input': inputs,\n",
    "        'output': outputs,\n",
    "        'instruction': instructions\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb8ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longuer =  2006\n",
      "exemple :  ['negative', 'Partnership', 'Competition', 'Partnership', 'negative', 'negative', 'Competition', 'negative', 'negative', 'Sale-Purchase']\n",
      "longuer =  8028\n",
      "exemple :  ['negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'Competition', 'negative', 'Competition']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2006/2006 [00:00<00:00, 59768.38 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 8028/8028 [00:00<00:00, 149693.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 2006\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 8028\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_finred_dataset('mydata/train.sent', 'mydata/train.tup', with_orig=False, with_cls=True)\n",
    "test_dataset = get_finred_dataset('mydata/test.sent', 'mydata/test.tup', with_orig=False, with_cls=True)\n",
    "\n",
    "finred_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "finred_dataset.save_to_disk('fingpt-finred')\n",
    "finred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1bfc53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'instruction'],\n",
       "    num_rows: 3210\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_finred_dataset('mydata/train.sent', 'mydata/train.tup', with_orig=True, with_cls=False)\n",
    "test_dataset = get_finred_dataset('mydata/test.sent', 'mydata/test.tup', with_orig=True, with_cls=False)\n",
    "\n",
    "finred_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "finred_dataset.save_to_disk('fingpt-finred-re')\n",
    "finred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7f1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8019d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "793fc820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005600690841674805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 17110,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1cce16e3de4d49ae7ac66647e093a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'instruction'],\n",
       "    num_rows: 17110\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict, question_dict = {}, {}\n",
    "for i, row in docs.iterrows():\n",
    "    doc_dict[row['docid']] = row['doc']\n",
    "for i, row in questions.iterrows():\n",
    "    question_dict[row['qid']] = row['question']\n",
    "    \n",
    "instruction_templates = [\n",
    "    \"Utilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.\",\n",
    "    \"Offer your insights or judgment on the input financial query or topic using your financial expertise. Reply as normal question answering\",\n",
    "    \"Based on your financial expertise, provide your response or viewpoint on the given financial question or topic. The response format is open.\",\n",
    "    \"Share your insights or perspective on the financial matter presented in the input.\",\n",
    "    \"Offer your thoughts or opinion on the input financial query or topic using your financial background.\"\n",
    "]\n",
    "\n",
    "inputs, outputs, instructions = [], [], []\n",
    "for i, row in qa_pairs.iterrows():\n",
    "    qid, docid = row['qid'], row['docid']\n",
    "    q = str(question_dict[qid])\n",
    "    doc = str(doc_dict[docid])\n",
    "    inputs.append(q)\n",
    "    outputs.append(doc)\n",
    "    instructions.append(instruction_templates[i%5])\n",
    "\n",
    "fiqa_qa_dataset = Dataset.from_dict({\n",
    "    'input': inputs,\n",
    "    'output': outputs,\n",
    "    'instruction': instructions\n",
    "})\n",
    "fiqa_qa_dataset.save_to_disk('fingpt-fiqa_qa')\n",
    "fiqa_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c1378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1.dev0+ga6eabc2b.d20230428)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /users/melodi/mettaleb/.local/lib/python3.10/site-packages (from pyarrow) (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb28560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb65ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_parquet = pq.read_table(\"train.parquet\")\n",
    "\n",
    "dataframe_parquet = table_parquet.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0d0539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27558, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_parquet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6e9e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3280f791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7a285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
